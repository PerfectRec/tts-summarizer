[
  {
    "type": "main_title",
    "content": "Verus: A Practical Foundation for Systems Verification",
    "page": 1,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "improved_author_info",
    "content": "There are 14 authors, including [break0.6]Andrea Lattuada from MPI-SWS, [break0.6]Travis Hance, Chanhee Cho from Carnegie Mellon University, [break0.6]Jay Bosamiya from Microsoft Research, [break0.6]Matthias Brun from ETH Zurich",
    "page": 1,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "abstract_heading",
    "content": "[break0.7]Abstract[break0.7]",
    "page": 1,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "abstract_content",
    "content": "Formal verification is a promising approach to eliminate bugs at compile time, before they ship. Indeed, our community has verified a wide variety of system software. However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains, or sacrificed expressiveness for powerful proof automation.\nBuilding on prior work on Verus, we aim to enable faster, cheaper verification of rich properties for realistic systems. We do so by integrating and optimizing the best choices from prior systems, tuning our design to overcome barriers encountered in those systems, and introducing novel techniques.\nWe evaluate Verus’s effectiveness with a wide variety of case-study systems, including distributed systems, an OS page table, a library for NUMA-aware concurrent data structure replication, a crash-safe storage system, and a concurrent memory allocator, together comprising 6.1k lines of implementation and 31k lines of proof. Verus verifies code 3–61× faster and with less effort than the state of the art.\nOur results suggest that Verus offers a platform for exploring the next frontiers in system-verification research. Because Verus builds on Rust, Verus is also positioned for wider use in production by developers who have already adopted Rust in the pursuit of more robust systems.",
    "page": 1,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]1 Introduction[break0.7]",
    "page": 1,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Society increasingly counts on the correctness, reliability, and security of system software. Such software is often inherently low-level, since higher-level software depends on it for foundational abstractions like unlimited virtual memory or reliable operation. System software must also hit stringent performance targets, since it sits on the critical path for the software above it. However, performance optimizations, especially those involving concurrency, add complexity. Unsurprisingly, these systems are notoriously difficult to get right. Formally verifying software is a promising approach for ensuring its correctness and reliability. Indeed, our community has seen a series of successful demonstrations verifying a wide variety of system software. However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains, or sacrificed expressiveness for powerful automation. In our work,we aim to enable faster,easier verification of rich properties for realistic systems.We do so by integrating and optimizing the best choices from prior systems,tuning and optimizing the best choices from prior systems,tuning",
    "page": 1,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Society increasingly counts on the correctness, reliability, and security of system software (i.e., fundamental software infrastructure such as operating systems, operating system databases, memory allocators, and libraries for cryptography and distributed protocols). Such software is often inherently low-level (e.g., manipulating raw bytes, interfacing directly with devices, or operating without a garbage collector), since higher-level software depends on it for foundational abstractions like unlimited virtual memory or reliable operation. System software must also hit stringent performance targets, since it sits on the critical path for the software above it. However, performance optimizations, especially those involving concurrency, add complexity. Unsurprisingly, these systems are notoriously difficult to get right. Formally verifying software is a promising approach for ensuring its correctness and reliability. Indeed, our community has seen a series of successful demonstrations verifying a wide variety of system software (§5). However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains (e.g., crash safety [1–3]), or sacrificed expressiveness for powerful automation [1–4 ,9]. In our work,we aim to enable faster,easier verification of rich properties for realistic systems.We do so by integrating and optimizing the best choices from prior systems,tuning and optimizing the best choices from prior systems,tuning",
      "textWithCitationsRemoved": "Society increasingly counts on the correctness, reliability, and security of system software. Such software is often inherently low-level, since higher-level software depends on it for foundational abstractions like unlimited virtual memory or reliable operation. System software must also hit stringent performance targets, since it sits on the critical path for the software above it. However, performance optimizations, especially those involving concurrency, add complexity. Unsurprisingly, these systems are notoriously difficult to get right. Formally verifying software is a promising approach for ensuring its correctness and reliability. Indeed, our community has seen a series of successful demonstrations verifying a wide variety of system software. However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains, or sacrificed expressiveness for powerful automation. In our work,we aim to enable faster,easier verification of rich properties for realistic systems.We do so by integrating and optimizing the best choices from prior systems,tuning and optimizing the best choices from prior systems,tuning"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "our design to overcome barriers they encountered, and introducing novel techniques to simplify concurrency reasoning.\n\nWe integrate our work into Verus, a tool designed to verify Rust code. Early work on Verus focused on designing and formalizing techniques for generating verification queries for both safe and unsafe Rust code. In this work, we describe our efforts to make Verus a powerful framework for system verification, and we evaluate our new system-relevant features in systems code (see section 5 for a deeper comparison). Our ambition is two-fold: first, to make Verus a foundation for exploring the next frontier in system verification research, and second, to open system verification to a broad community of developers without deep verification expertise.\n\nCore to Verus is the acknowledgment that verifying system software entails many kinds of reasoning at many different levels of abstraction (section 2), from low-level details of memory access and bit manipulation, to the high-level challenges of defining and proving that a file system is crash-safe or that a distributed system achieves consensus. Rather than tackle this complexity with a single generic solution, Verus carefully organizes proof obligations in a way that plays to the strengths of various proof automation strategies, and hence minimizes developer effort.\n\nAcross all proof levels, Verus integrates two powerful reasoning techniques. By default, it provides aggressively optimized versions of general-purpose, semi-automated reasoning techniques (section 3 point 1) that have shown success in one line of verified systems. For portions of the system that can be described in EPR, which is a restricted logic language known as effectively propositional logic or EPR logic language , Verus shows how to soundly integrate another line of work so proofs of these portions are fully automated (section 3 point 2).\n\nVerus also includes custom automation for reasoning challenges at specific levels in real systems. For example, certain coding idioms like bit manipulations and nonlinear arithmetic confound prior tools; our Verus extensions add dedicated support for such idioms (section 3 point 3). Real systems also exploit shared-memory concurrency, so we extend Verus (section 3 point 4) to allow a developer to describe a plan for sharing state across threads , show that threads locally obey the plan ,and create invariants about the global program state from the plan.\n\nEvaluating a new general-purpose system verification framework is challenging , given that entire papers have been devoted to verifying a single system . Hence we adopt a multi-level evaluation . We start with a set of verification “mini-benchmarks”: programs we verify in Verus and in five comparable tools . This helps us assess the impact of Verus’s design decisions on verification performance in examples small enough to analyze in some detail .\n\nWe show that the benefits seen at small scale extend to larger systems by porting the specifications , code ,and proofs from several prior large-scale verification efforts to Verus and comparing the developer experience in terms of verification time and developer effort . These case studies include a distributed system client and a library that creates a linearizable NUMA-aware concurrent data structure from a black-box sequential one .\n\nOf course , starting from correct code and successful proofs is overly optimistic , so we also evaluate similar metrics as we verify three new system components from scratch , including an operating system page table ,a concurrent memory allocator ,and storage system designed for production . While our results are positive ,the true evaluation will come from future projects using Verus to verify systems at new levels of scale and complexity . Indeed ,other research groups have already used Verus to produce verified cluster-management controllers ,a verified microkernel ,a security module for confidential virtual machines ,and verify large language model produced code .\n\nAny verification result is limited by its trusted computing base .Verus’s results depend on correctness top-level specifications ,the verifiers used by verifiers ,the solvers it relies on,and rust compilers.",
    "page": 2,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "our design to overcome barriers they encountered, and introducing novel techniques to simplify concurrency reasoning.\n\nWe integrate our work into Verus, a tool designed to verify Rust code. Early work [10] on Verus focused on designing and formalizing techniques for generating verification queries for both safe and unsafe Rust code. In this work, we describe our efforts to make Verus a powerful framework for system verification, and we evaluate our new system-relevant features in systems code (see §5 for a deeper comparison). Our ambition is two-fold: first, to make Verus a foundation for exploring the next frontier in system verification research, and second, to open system verification to a broad community of developers without deep verification expertise.\n\nCore to Verus is the acknowledgment that verifying system software entails many kinds of reasoning at many different levels of abstraction (§2), from low-level details of memory access and bit manipulation, to the high-level challenges of defining and proving that a file system is crash-safe or that a distributed system achieves consensus. Rather than tackle this complexity with a single generic solution, Verus carefully organizes proof obligations in a way that plays to the strengths of various proof automation strategies, and hence minimizes developer effort.\n\nAcross all proof levels, Verus integrates two powerful reasoning techniques. By default, it provides aggressively optimized versions of general-purpose, semi-automated reasoning techniques (§3.1) that have shown success in one line of verified systems [11–16]. For portions of the system that can be described in EPR [17], a restricted logic, Verus shows how to soundly integrate another line of work [7, 8, 18–22] so proofs of these portions are fully automated (§3.2).\n\nVerus also includes custom automation for reasoning challenges at specific levels in real systems. For example, certain coding idioms like bit manipulations and nonlinear arithmetic confound prior tools; our Verus extensions add dedicated support for such idioms (§3.3). Real systems also exploit shared-memory concurrency, so we extend Verus (§3.4) to allow a developer to describe a plan for sharing state across threads, show that threads locally obey the plan, and create invariants about the global program state from the plan.\n\nEvaluating a new general-purpose system verification framework is challenging, given that entire papers have been devoted to verifying a single system. Hence we adopt a multi-level evaluation. We start with a set of verification “mini-benchmarks”: programs we verify in Verus and in five comparable tools. This helps us assess the impact of Verus’s design decisions on verification performance in examples small enough to analyze in some detail.\n\nWe show that the benefits seen at small scale extend to larger systems by porting the specifications, code, and proofs from several prior large-scale verification efforts to Verus and comparing the developer experience in terms of verification time and developer effort. These case studies include a distributed system client and a library that creates a linearizable NUMA-aware concurrent data structure from a black-box sequential one.\n\nOf course, starting from correct code and successful proofs is overly optimistic, so we also evaluate similar metrics as we verify three new system components from scratch, including an OS page table, a concurrent memory allocator, and a storage system designed for production. While our results are positive,^1 the true evaluation will come from future projects using Verus to verify systems at new levels of scale and complexity. Indeed, other research groups have already used Verus to produce verified cluster-management controllers [25], a verified microkernel [26], a security module for confidential VMs [27], and to verify LLM-produced code [28].\n\nAny verification result is limited by its TCB. Verus’s results depend on the correctness of the top-level specifications, the Verus verifier, the solvers it relies on, and the Rust compiler.",
      "textWithCitationsRemoved": "our design to overcome barriers they encountered, and introducing novel techniques to simplify concurrency reasoning.\n\nWe integrate our work into Verus, a tool designed to verify Rust code. Early work on Verus focused on designing and formalizing techniques for generating verification queries for both safe and unsafe Rust code. In this work, we describe our efforts to make Verus a powerful framework for system verification, and we evaluate our new system-relevant features in systems code (see §5 for a deeper comparison). Our ambition is two-fold: first, to make Verus a foundation for exploring the next frontier in system verification research, and second, to open system verification to a broad community of developers without deep verification expertise.\n\nCore to Verus is the acknowledgment that verifying system software entails many kinds of reasoning at many different levels of abstraction (§2), from low-level details of memory access and bit manipulation, to the high-level challenges of defining and proving that a file system is crash-safe or that a distributed system achieves consensus. Rather than tackle this complexity with a single generic solution, Verus carefully organizes proof obligations in a way that plays to the strengths of various proof automation strategies, and hence minimizes developer effort.\n\nAcross all proof levels, Verus integrates two powerful reasoning techniques. By default, it provides aggressively optimized versions of general-purpose, semi-automated reasoning techniques (§3.1) that have shown success in one line of verified systems. For portions of the system that can be described in EPR, a restricted logic, Verus shows how to soundly integrate another line of work so proofs of these portions are fully automated (§3.2).\n\nVerus also includes custom automation for reasoning challenges at specific levels in real systems. For example, certain coding idioms like bit manipulations and nonlinear arithmetic confound prior tools; our Verus extensions add dedicated support for such idioms (§3.3). Real systems also exploit shared-memory concurrency, so we extend Verus (§3.4) to allow a developer to describe a plan for sharing state across threads, show that threads locally obey the plan, and create invariants about the global program state from the plan.\n\nEvaluating a new general-purpose system verification framework is challenging, given that entire papers have been devoted to verifying a single system. Hence we adopt a multi-level evaluation. We start with a set of verification “mini-benchmarks”: programs we verify in Verus and in five comparable tools. This helps us assess the impact of Verus’s design decisions on verification performance in examples small enough to analyze in some detail.\n\nWe show that the benefits seen at small scale extend to larger systems by porting the specifications, code, and proofs from several prior large-scale verification efforts to Verus and comparing the developer experience in terms of verification time and developer effort. These case studies include a distributed system client and a library that creates a linearizable NUMA-aware concurrent data structure from a black-box sequential one.\n\nOf course, starting from correct code and successful proofs is overly optimistic, so we also evaluate similar metrics as we verify three new system components from scratch, including an OS page table, a concurrent memory allocator, and a storage system designed for production. While our results are positive, the true evaluation will come from future projects using Verus to verify systems at new levels of scale and complexity. Indeed, other research groups have already used Verus to produce verified cluster-management controllers, a verified microkernel, a security module for confidential VMs, and to verify LLM-produced code.\n\nAny verification result is limited by its TCB. Verus’s results depend on the correctness of the top-level specifications, the Verus verifier, the solvers it relies on, and the Rust compiler."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "our design to overcome barriers they encountered, and introducing novel techniques to simplify concurrency reasoning.\n\nWe integrate our work into Verus, a tool designed to verify Rust code. Early work on Verus focused on designing and formalizing techniques for generating verification queries for both safe and unsafe Rust code. In this work, we describe our efforts to make Verus a powerful framework for system verification, and we evaluate our new system-relevant features in systems code (see §5 for a deeper comparison). Our ambition is two-fold: first, to make Verus a foundation for exploring the next frontier in system verification research, and second, to open system verification to a broad community of developers without deep verification expertise.\n\nCore to Verus is the acknowledgment that verifying system software entails many kinds of reasoning at many different levels of abstraction (§2), from low-level details of memory access and bit manipulation, to the high-level challenges of defining and proving that a file system is crash-safe or that a distributed system achieves consensus. Rather than tackle this complexity with a single generic solution, Verus carefully organizes proof obligations in a way that plays to the strengths of various proof automation strategies, and hence minimizes developer effort.\n\nAcross all proof levels, Verus integrates two powerful reasoning techniques. By default, it provides aggressively optimized versions of general-purpose, semi-automated reasoning techniques (§3.1) that have shown success in one line of verified systems. For portions of the system that can be described in EPR, a restricted logic, Verus shows how to soundly integrate another line of work so proofs of these portions are fully automated (§3.2).\n\nVerus also includes custom automation for reasoning challenges at specific levels in real systems. For example, certain coding idioms like bit manipulations and nonlinear arithmetic confound prior tools; our Verus extensions add dedicated support for such idioms (§3.3). Real systems also exploit shared-memory concurrency, so we extend Verus (§3.4) to allow a developer to describe a plan for sharing state across threads, show that threads locally obey the plan, and create invariants about the global program state from the plan.\n\nEvaluating a new general-purpose system verification framework is challenging, given that entire papers have been devoted to verifying a single system. Hence we adopt a multi-level evaluation. We start with a set of verification “mini-benchmarks”: programs we verify in Verus and in five comparable tools. This helps us assess the impact of Verus’s design decisions on verification performance in examples small enough to analyze in some detail.\n\nWe show that the benefits seen at small scale extend to larger systems by porting the specifications, code, and proofs from several prior large-scale verification efforts to Verus and comparing the developer experience in terms of verification time and developer effort. These case studies include a distributed system client and a library that creates a linearizable NUMA-aware concurrent data structure from a black-box sequential one.\n\nOf course, starting from correct code and successful proofs is overly optimistic, so we also evaluate similar metrics as we verify three new system components from scratch, including an OS page table, a concurrent memory allocator, and a storage system designed for production. While our results are positive, the true evaluation will come from future projects using Verus to verify systems at new levels of scale and complexity. Indeed, other research groups have already used Verus to produce verified cluster-management controllers, a verified microkernel, a security module for confidential VMs, and to verify LLM-produced code.\n\nAny verification result is limited by its TCB. Verus’s results depend on the correctness of the top-level specifications, the Verus verifier, the solvers it relies on, and the Rust compiler.",
      "wordedReplacement": "our design to overcome barriers they encountered, and introducing novel techniques to simplify concurrency reasoning.\n\nWe integrate our work into Verus, a tool designed to verify Rust code. Early work on Verus focused on designing and formalizing techniques for generating verification queries for both safe and unsafe Rust code. In this work, we describe our efforts to make Verus a powerful framework for system verification, and we evaluate our new system-relevant features in systems code (see section 5 for a deeper comparison). Our ambition is two-fold: first, to make Verus a foundation for exploring the next frontier in system verification research, and second, to open system verification to a broad community of developers without deep verification expertise.\n\nCore to Verus is the acknowledgment that verifying system software entails many kinds of reasoning at many different levels of abstraction (section 2), from low-level details of memory access and bit manipulation, to the high-level challenges of defining and proving that a file system is crash-safe or that a distributed system achieves consensus. Rather than tackle this complexity with a single generic solution, Verus carefully organizes proof obligations in a way that plays to the strengths of various proof automation strategies, and hence minimizes developer effort.\n\nAcross all proof levels, Verus integrates two powerful reasoning techniques. By default, it provides aggressively optimized versions of general-purpose, semi-automated reasoning techniques (section 3 point 1) that have shown success in one line of verified systems. For portions of the system that can be described in EPR, which is a restricted logic language known as effectively propositional logic or EPR logic language , Verus shows how to soundly integrate another line of work so proofs of these portions are fully automated (section 3 point 2).\n\nVerus also includes custom automation for reasoning challenges at specific levels in real systems. For example, certain coding idioms like bit manipulations and nonlinear arithmetic confound prior tools; our Verus extensions add dedicated support for such idioms (section 3 point 3). Real systems also exploit shared-memory concurrency, so we extend Verus (section 3 point 4) to allow a developer to describe a plan for sharing state across threads , show that threads locally obey the plan ,and create invariants about the global program state from the plan.\n\nEvaluating a new general-purpose system verification framework is challenging , given that entire papers have been devoted to verifying a single system . Hence we adopt a multi-level evaluation . We start with a set of verification “mini-benchmarks”: programs we verify in Verus and in five comparable tools . This helps us assess the impact of Verus’s design decisions on verification performance in examples small enough to analyze in some detail .\n\nWe show that the benefits seen at small scale extend to larger systems by porting the specifications , code ,and proofs from several prior large-scale verification efforts to Verus and comparing the developer experience in terms of verification time and developer effort . These case studies include a distributed system client and a library that creates a linearizable NUMA-aware concurrent data structure from a black-box sequential one .\n\nOf course , starting from correct code and successful proofs is overly optimistic , so we also evaluate similar metrics as we verify three new system components from scratch , including an operating system page table ,a concurrent memory allocator ,and storage system designed for production . While our results are positive ,the true evaluation will come from future projects using Verus to verify systems at new levels of scale and complexity . Indeed ,other research groups have already used Verus to produce verified cluster-management controllers ,a verified microkernel ,a security module for confidential virtual machines ,and verify large language model produced code .\n\nAny verification result is limited by its trusted computing base .Verus’s results depend on correctness top-level specifications ,the verifiers used by verifiers ,the solvers it relies on,and rust compilers."
    },
    "optimizedMath": true
  },
  {
    "type": "heading",
    "content": "[break0.7]In summary, we:[break0.7]",
    "page": 2,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Present the systems-relevant aspects of Verus’s design (§3), unifying prior approaches in a single framework and simplifying system proofs via novel techniques.\n\nShow how to soundly provide the proof-free automation achieved by prior work without sacrificing expressiveness or developer freedom.\n\nDescribe VerusSync, Verus’s new approach to allowing the developer to reason about concurrent execution at the level of their application without relying on heavyweight logical objects required by prior work.\n\nEvaluate Verus as a system verification language against millibenchmarks and five case studies, producing over 6.1K lines of implementation and 31K lines of proof. These case studies show how Verus’s features support verifying a variety of systems for correctness and reliability. Verus also produces verification results orders of magnitude faster than prior automated tools.",
    "page": 2,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Present the systems-relevant aspects of Verus’s design (§3), unifying prior approaches in a single framework and simplifying system proofs via novel techniques.\n\nShow how to soundly provide the proof-free automation achieved by prior work [7, 8, 18–22] without sacrificing expressiveness or developer freedom.\n\nDescribe VerusSync, Verus’s new approach to allowing the developer to reason about concurrent execution at the level of their application without relying on heavyweight logical objects required by prior work [3, 29, 30].\n\nEvaluate Verus as a system verification language against millibenchmarks and five case studies, producing over 6.1K lines of implementation and 31K lines of proof. These case studies show how Verus’s features support verifying a variety of systems for correctness and reliability. Verus also produces verification results orders of magnitude faster than prior automated tools.",
      "textWithCitationsRemoved": "Present the systems-relevant aspects of Verus’s design (§3), unifying prior approaches in a single framework and simplifying system proofs via novel techniques.\n\nShow how to soundly provide the proof-free automation achieved by prior work without sacrificing expressiveness or developer freedom.\n\nDescribe VerusSync, Verus’s new approach to allowing the developer to reason about concurrent execution at the level of their application without relying on heavyweight logical objects required by prior work.\n\nEvaluate Verus as a system verification language against millibenchmarks and five case studies, producing over 6.1K lines of implementation and 31K lines of proof. These case studies show how Verus’s features support verifying a variety of systems for correctness and reliability. Verus also produces verification results orders of magnitude faster than prior automated tools."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]2 Verus Overview: Verification for Systems[break0.7]",
    "page": 2,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "When constructing a complex system, developers typically tame the complexity by thinking about the system at different levels of abstraction. These range from low-level concerns like memory safety to high-level concerns like crash safety. Each level is challenging, but the ultimate challenge is ensuring that all of the levels together produce a correct system.\n\nAs detailed in Figure 1, Verus helps developers with every aspect of this reasoning. Below, we provide an overview of Verus’s key features. Given space constraints, the subsequent sections then provide more details on a selection of those features. §4 evaluates the overall impact on system verification.",
    "page": 2,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 1  summary:\nThe figure provides an overview of Verus, a system designed for automated and semi-automated reasoning across the full system stack. It illustrates how Verus integrates various reasoning techniques tailored to specific levels of the stack. The diagram is structured hierarchically, showing different components such as memory reasoning, system idioms, multi-threading, and system-level reasoning. Each component is connected, indicating how Verus applies these techniques to enhance system verification. The figure emphasizes Verus's capability to balance automation and expressiveness, offering optimized proof techniques and full automation for specific cases.",
    "page": 3,
    "label": {
      "labelType": "Figure",
      "labelNumber": "1",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Cross-Layer Proof Automation.[break0.7]",
    "page": 2,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "At the scale of complexity in modern systems, encoding both the code and the abstractions needed to reason about it in a mechanized form, if done naively, can lead to huge proof obligations. Prior work tries to tame the complexity of proving correctness by",
    "page": 2,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "At the scale of complexity in modern systems, encoding both the code and the abstractions needed to reason about it in a mechanized form, if done naively, can lead to huge proof obligations. Prior work (§5) tries to tame the complexity of proving correctness by",
      "textWithCitationsRemoved": "At the scale of complexity in modern systems, encoding both the code and the abstractions needed to reason about it in a mechanized form, if done naively, can lead to huge proof obligations. Prior work tries to tame the complexity of proving correctness by"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "sacrificing either automation or expressiveness. Verus instead combines the best of both worlds, providing aggressively optimized, general-purpose, semi-automated proof techniques that improve on prior widely-used tools, plus full proof automation for special cases.\n\nVerus also includes reasoning techniques tuned for particular levels in the stack, smoothing out aspects of system verification that prior work has struggled with.\n\nMemory Reasoning. Rather than proving the memory safety of system code via an expensive combination of manual developer effort and/or complex encodings, Verus stands on the shoulders of the Rust community’s extensive work on ensuring safety through a fast, deterministic type checker. Rust’s ownership-based type checker enforces that only one variable has exclusive ownership of any object at a time. Rust’s growing developer population and large-scale projects in the Linux kernel, at Amazon, and at Google, validate that developers can use Rust’s types to verify memory safety for real systems.\n\nRust includes an “escape hatch” that allows developers to write explicitly labeled unsafe code, wherein the developer accepts the obligation to ensure the code’s safety, which challenges even experts. Fortunately, Verus can verify a subset of unsafe Rust features, and it rejects usage of features outside that subset. In this work, to support our case studies, we extended Verus’s support for raw pointers.\n\nHence, Verus gives programmers C-like freedom to manage and manipulate memory, and yet it automatically proves memory safety of almost all such code.\n\nSystem Idioms. At the next level, Verus includes reasoning techniques specifically designed for thorny system idioms that the community’s experiences indicate are challenging to generically automate. These include bit manipulation and nonlinear arithmetic.\n\nMulti-Threading. Higher up in the stack, many systems rely on concurrency for good performance, via local multi-threaded execution. Concurrent execution makes verification significantly more complex and automation challenging, since both the verifier and the developer must now consider how each thread interacts with every other thread.",
    "page": 3,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "sacrificing either automation or expressiveness. Verus instead combines the best of both worlds, providing aggressively optimized, general-purpose, semi-automated proof techniques (§3.1) that improve on prior widely-used tools, plus full proof automation for special cases (§3.2).\n\nVerus also includes reasoning techniques tuned for particular levels in the stack, smoothing out aspects of system verification that prior work has struggled with.\n\nMemory Reasoning. Rather than proving the memory safety of system code via an expensive combination of manual developer effort [31–33] and/or complex encodings [11, 34, 35], Verus stands on the shoulders of the Rust [36, 37] community’s extensive work on ensuring safety through a fast, deterministic type checker. Rust’s ownership-based type checker enforces that only one variable has exclusive ownership of any object at a time. Rust’s growing developer population and large-scale projects in the Linux kernel [38], at Amazon [39], and at Google [40], validate that developers can use Rust’s types to verify memory safety for real systems.\n\nRust includes an “escape hatch” that allows developers to write explicitly labeled unsafe code, wherein the developer accepts the obligation to ensure the code’s safety, which challenges even experts [41]. Fortunately, Verus can verify a subset of unsafe Rust features [10], and it rejects usage of features outside that subset. In this work, to support our case studies (§4.2), we extended Verus’s support for raw pointers.\n\nHence, Verus gives programmers C-like freedom to manage and manipulate memory, and yet it automatically proves memory safety of almost all such code.\n\nSystem Idioms. At the next level, Verus includes reasoning techniques (§3.3) specifically designed for thorny system idioms that the community’s experiences indicate are challenging to generically automate. These include bit manipulation [12, 42] and nonlinear arithmetic [12, 43, 44].\n\nMulti-Threading. Higher up in the stack, many systems rely on concurrency for good performance, via local multi-threaded execution. Concurrent execution makes verification significantly more complex and automation challenging, since both the verifier and the developer must now consider how each thread interacts with every other thread.",
      "textWithCitationsRemoved": "sacrificing either automation or expressiveness. Verus instead combines the best of both worlds, providing aggressively optimized, general-purpose, semi-automated proof techniques that improve on prior widely-used tools, plus full proof automation for special cases.\n\nVerus also includes reasoning techniques tuned for particular levels in the stack, smoothing out aspects of system verification that prior work has struggled with.\n\nMemory Reasoning. Rather than proving the memory safety of system code via an expensive combination of manual developer effort and/or complex encodings, Verus stands on the shoulders of the Rust community’s extensive work on ensuring safety through a fast, deterministic type checker. Rust’s ownership-based type checker enforces that only one variable has exclusive ownership of any object at a time. Rust’s growing developer population and large-scale projects in the Linux kernel, at Amazon, and at Google, validate that developers can use Rust’s types to verify memory safety for real systems.\n\nRust includes an “escape hatch” that allows developers to write explicitly labeled unsafe code, wherein the developer accepts the obligation to ensure the code’s safety, which challenges even experts. Fortunately, Verus can verify a subset of unsafe Rust features, and it rejects usage of features outside that subset. In this work, to support our case studies, we extended Verus’s support for raw pointers.\n\nHence, Verus gives programmers C-like freedom to manage and manipulate memory, and yet it automatically proves memory safety of almost all such code.\n\nSystem Idioms. At the next level, Verus includes reasoning techniques specifically designed for thorny system idioms that the community’s experiences indicate are challenging to generically automate. These include bit manipulation and nonlinear arithmetic.\n\nMulti-Threading. Higher up in the stack, many systems rely on concurrency for good performance, via local multi-threaded execution. Concurrent execution makes verification significantly more complex and automation challenging, since both the verifier and the developer must now consider how each thread interacts with every other thread."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "sacrificing either automation or expressiveness. Verus instead combines the best of both worlds, providing aggressively optimized, general-purpose, semi-automated proof techniques that improve on prior widely-used tools, plus full proof automation for special cases.\n\nVerus also includes reasoning techniques tuned for particular levels in the stack, smoothing out aspects of system verification that prior work has struggled with.\n\nMemory Reasoning. Rather than proving the memory safety of system code via an expensive combination of manual developer effort and/or complex encodings, Verus stands on the shoulders of the Rust community’s extensive work on ensuring safety through a fast, deterministic type checker. Rust’s ownership-based type checker enforces that only one variable has exclusive ownership of any object at a time. Rust’s growing developer population and large-scale projects in the Linux kernel, at Amazon, and at Google, validate that developers can use Rust’s types to verify memory safety for real systems.\n\nRust includes an “escape hatch” that allows developers to write explicitly labeled unsafe code, wherein the developer accepts the obligation to ensure the code’s safety, which challenges even experts. Fortunately, Verus can verify a subset of unsafe Rust features, and it rejects usage of features outside that subset. In this work, to support our case studies, we extended Verus’s support for raw pointers.\n\nHence, Verus gives programmers C-like freedom to manage and manipulate memory, and yet it automatically proves memory safety of almost all such code.\n\nSystem Idioms. At the next level, Verus includes reasoning techniques specifically designed for thorny system idioms that the community’s experiences indicate are challenging to generically automate. These include bit manipulation and nonlinear arithmetic.\n\nMulti-Threading. Higher up in the stack, many systems rely on concurrency for good performance, via local multi-threaded execution. Concurrent execution makes verification significantly more complex and automation challenging, since both the verifier and the developer must now consider how each thread interacts with every other thread.",
      "wordedReplacement": "sacrificing either automation or expressiveness. Verus instead combines the best of both worlds, providing aggressively optimized, general-purpose, semi-automated proof techniques that improve on prior widely-used tools, plus full proof automation for special cases.\n\nVerus also includes reasoning techniques tuned for particular levels in the stack, smoothing out aspects of system verification that prior work has struggled with.\n\nMemory Reasoning. Rather than proving the memory safety of system code via an expensive combination of manual developer effort and/or complex encodings, Verus stands on the shoulders of the Rust community’s extensive work on ensuring safety through a fast, deterministic type checker. Rust’s ownership-based type checker enforces that only one variable has exclusive ownership of any object at a time. Rust’s growing developer population and large-scale projects in the Linux kernel, at Amazon, and at Google, validate that developers can use Rust’s types to verify memory safety for real systems.\n\nRust includes an “escape hatch” that allows developers to write explicitly labeled unsafe code, wherein the developer accepts the obligation to ensure the code’s safety, which challenges even experts. Fortunately, Verus can verify a subset of unsafe Rust features, and it rejects usage of features outside that subset. In this work, to support our case studies, we extended Verus’s support for raw pointers.\n\nHence, Verus gives programmers C-like freedom to manage and manipulate memory, and yet it automatically proves memory safety of almost all such code.\n\nSystem Idioms. At the next level, Verus includes reasoning techniques specifically designed for thorny system idioms that the community’s experiences indicate are challenging to generically automate. These include bit manipulation and nonlinear arithmetic.\n\nMulti-Threading. Higher up in the stack, many systems rely on concurrency for good performance, via local multi-threaded execution. Concurrent execution makes verification significantly more complex and automation challenging, since both the verifier and the developer must now consider how each thread interacts with every other thread."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "Verus includes VerusSync, a domain-specific language for reasoning about multi-threaded code directly in terms of the application’s logic, ultimately producing an abstraction of the application that encapsulates the complexity of threads, locks, and other synchronization concerns.\n\nSystem-Level Reasoning. At the top level, developers often wish to prove more than the correctness of a program in isolation; they want richer properties of the program executing in a larger context. For example, a distributed system may run several instances of the program; we want the whole system to be reliable. A storage program interacts asynchronously with an external disk; we want the system to be correct even as the program crashes and restarts.\n\nExtensive prior work has demonstrated the generality and effectiveness of modeling this system-level reasoning in terms of atomic state machines that capture true system state and how it evolves, so Verus supports such reasoning as a special case of VerusSync.",
    "page": 3,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Verus includes VerusSync (§3.4), a domain-specific language for reasoning about multi-threaded code directly in terms of the application’s logic, ultimately producing an abstraction of the application that encapsulates the complexity of threads, locks, and other synchronization concerns.\n\nSystem-Level Reasoning. At the top level, developers often wish to prove more than the correctness of a program in isolation; they want richer properties of the program executing in a larger context. For example, a distributed system may run several instances of the program; we want the whole system to be reliable. A storage program interacts asynchronously with an external disk; we want the system to be correct even as the program crashes and restarts.\n\nExtensive prior work [12, 13, 16, 29, 42] has demonstrated the generality and effectiveness of modeling this system-level reasoning in terms of atomic state machines [45] that capture true system state and how it evolves, so Verus supports such reasoning as a special case of VerusSync.",
      "textWithCitationsRemoved": "Verus includes VerusSync, a domain-specific language for reasoning about multi-threaded code directly in terms of the application’s logic, ultimately producing an abstraction of the application that encapsulates the complexity of threads, locks, and other synchronization concerns.\n\nSystem-Level Reasoning. At the top level, developers often wish to prove more than the correctness of a program in isolation; they want richer properties of the program executing in a larger context. For example, a distributed system may run several instances of the program; we want the whole system to be reliable. A storage program interacts asynchronously with an external disk; we want the system to be correct even as the program crashes and restarts.\n\nExtensive prior work has demonstrated the generality and effectiveness of modeling this system-level reasoning in terms of atomic state machines that capture true system state and how it evolves, so Verus supports such reasoning as a special case of VerusSync."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]3 Key Aspects of Verus’s Design for Systems[break0.7]",
    "page": 3,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Here we highlight several key ideas and design decisions that enable Verus to support the verification of complex systems.",
    "page": 3,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]3.1 Streamlined, General-Purpose Automation[break0.7]",
    "page": 3,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Motivation. Some of the largest verified system implementations have relied on semi-automated program verifiers like VCC, Dafny, or F star. Compared to theorem provers, these tools do not require fully verified programs, as opposed to general math theorems. While they sacrifice expressivity compared with theorem provers, they still include general-purpose reasoning techniques that allow them to be adapted for different settings. Most importantly, by providing significant automation \"out of the box\", typically by converting the question of code or proof correctness into a query to an SMT (Satisfiability Modulo Theories) solver (for example, Z3). The SMT solver then attempts to automatically prove the query by combining fast satisfiability solving with specialized solvers for theories like integer arithmetic, and heuristics for handling quantifiers. However, existing program verifiers struggle in the face of modern system complexity, often forcing developers to break their code into unnaturally small units and or to tolerate long code-prover cycles.\n\nOur Approach. Verus's default mode, used in the majority of our proofs, is carefully to utilize its underlying SMT solver as efficiently as possible. To illustrate, Figure 2 shows a simple example of verifiable code written in Verus. The verus macro extends Rust with annotations to guide verification. For example, the requires and ensures annotations introduce pre- and postconditions that specify correctness for executable Rust functions like pop. These specs refer to auxiliary spec functions, like the view function that abstracts a concrete LinkedList implementation as a mathematical Seq. Internally, Verus employs standard Floyd-Hoare logic to convert proof obligations, such as pop's",
    "page": 3,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Motivation. Some of the largest verified system implementations [11–16] have relied on semi-automated program verifiers like VCC [11], Dafny [34], or F* [35]. Compared to theorem provers [31, 32], these tools do not require fully verified programs, as opposed to general math theorems. While they sacrifice expressivity compared with theorem provers, they still include general-purpose reasoning techniques that allow them to be adapted for different settings. Most importantly, by providing significant automation “out of the box”, typically by converting the question of code (or proof) correctness into a query to an SMT (Satisfiability Modulo Theories) solver (e.g., Z3 [46]). The SMT solver then attempts to automatically prove the query by combining fast satisfiability solving with specialized solvers for theories like integer arithmetic, and heuristics for handling quantifiers. However, existing program verifiers struggle in the face of modern system complexity, often forcing developers to break their code into unnaturally small units and/or to tolerate long code-prover cycles.\n\nOur Approach. Verus’s default mode, used in the majority of our proofs, is carefully to utilize its underlying SMT solver as efficiently as possible. To illustrate, Figure 2 shows a simple example of verifiable code written in Verus. The verus! macro extends Rust with annotations to guide verification. For example, the requires and ensures annotations introduce pre- and postconditions that specify correctness for executable Rust functions like pop. These specs refer to auxiliary spec functions, like the view function that abstracts a concrete LinkedList implementation as a mathematical Seq. Internally, Verus employs standard Floyd-Hoare logic [47, 48] to convert proof obligations, such as pop's",
      "textWithCitationsRemoved": "Motivation. Some of the largest verified system implementations have relied on semi-automated program verifiers like VCC, Dafny, or F*. Compared to theorem provers, these tools do not require fully verified programs, as opposed to general math theorems. While they sacrifice expressivity compared with theorem provers, they still include general-purpose reasoning techniques that allow them to be adapted for different settings. Most importantly, by providing significant automation “out of the box”, typically by converting the question of code (or proof) correctness into a query to an SMT (Satisfiability Modulo Theories) solver (e.g., Z3). The SMT solver then attempts to automatically prove the query by combining fast satisfiability solving with specialized solvers for theories like integer arithmetic, and heuristics for handling quantifiers. However, existing program verifiers struggle in the face of modern system complexity, often forcing developers to break their code into unnaturally small units and/or to tolerate long code-prover cycles.\n\nOur Approach. Verus’s default mode, used in the majority of our proofs, is carefully to utilize its underlying SMT solver as efficiently as possible. To illustrate, Figure 2 shows a simple example of verifiable code written in Verus. The verus! macro extends Rust with annotations to guide verification. For example, the requires and ensures annotations introduce pre- and postconditions that specify correctness for executable Rust functions like pop. These specs refer to auxiliary spec functions, like the view function that abstracts a concrete LinkedList implementation as a mathematical Seq. Internally, Verus employs standard Floyd-Hoare logic to convert proof obligations, such as pop's"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "Motivation. Some of the largest verified system implementations have relied on semi-automated program verifiers like VCC, Dafny, or F*. Compared to theorem provers, these tools do not require fully verified programs, as opposed to general math theorems. While they sacrifice expressivity compared with theorem provers, they still include general-purpose reasoning techniques that allow them to be adapted for different settings. Most importantly, by providing significant automation “out of the box”, typically by converting the question of code (or proof) correctness into a query to an SMT (Satisfiability Modulo Theories) solver (e.g., Z3). The SMT solver then attempts to automatically prove the query by combining fast satisfiability solving with specialized solvers for theories like integer arithmetic, and heuristics for handling quantifiers. However, existing program verifiers struggle in the face of modern system complexity, often forcing developers to break their code into unnaturally small units and/or to tolerate long code-prover cycles.\n\nOur Approach. Verus’s default mode, used in the majority of our proofs, is carefully to utilize its underlying SMT solver as efficiently as possible. To illustrate, Figure 2 shows a simple example of verifiable code written in Verus. The verus! macro extends Rust with annotations to guide verification. For example, the requires and ensures annotations introduce pre- and postconditions that specify correctness for executable Rust functions like pop. These specs refer to auxiliary spec functions, like the view function that abstracts a concrete LinkedList implementation as a mathematical Seq. Internally, Verus employs standard Floyd-Hoare logic to convert proof obligations, such as pop's",
      "wordedReplacement": "Motivation. Some of the largest verified system implementations have relied on semi-automated program verifiers like VCC, Dafny, or F star. Compared to theorem provers, these tools do not require fully verified programs, as opposed to general math theorems. While they sacrifice expressivity compared with theorem provers, they still include general-purpose reasoning techniques that allow them to be adapted for different settings. Most importantly, by providing significant automation \"out of the box\", typically by converting the question of code or proof correctness into a query to an SMT (Satisfiability Modulo Theories) solver (for example, Z3). The SMT solver then attempts to automatically prove the query by combining fast satisfiability solving with specialized solvers for theories like integer arithmetic, and heuristics for handling quantifiers. However, existing program verifiers struggle in the face of modern system complexity, often forcing developers to break their code into unnaturally small units and or to tolerate long code-prover cycles.\n\nOur Approach. Verus's default mode, used in the majority of our proofs, is carefully to utilize its underlying SMT solver as efficiently as possible. To illustrate, Figure 2 shows a simple example of verifiable code written in Verus. The verus macro extends Rust with annotations to guide verification. For example, the requires and ensures annotations introduce pre- and postconditions that specify correctness for executable Rust functions like pop. These specs refer to auxiliary spec functions, like the view function that abstracts a concrete LinkedList implementation as a mathematical Seq. Internally, Verus employs standard Floyd-Hoare logic to convert proof obligations, such as pop's"
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "postcondition into verification conditions to send to an SMT solver, which automatically determines whether the formula holds for all possible function inputs.\n\nThe approach of converting proof obligations to verification conditions is standard in many verification frameworks, but the details of language design and implementation have a big effect on the efficiency of the SMT queries. We summarize some of these design choices here.\n\nVerus considers when queries are simpler and smaller by orders of magnitude to the SMT solver, which translates to significantly faster verification, so for a given verification problem, Verus can provide a more efficient code-prove cycle. Or conversely, given the same time budget as an existing tool, Verus can tackle larger verification problems.\n\nUnlike specification functions in Dafny and F star , Verus Spec functions are pure, total mathematical functions with no preconditions or direct access to the heap. Thus they can be directly encoded as SMT functions without the additional baggage of prior tools. As prior work explains, Rust’s type system means that explicit heap-based reasoning is rarely needed, and when it is needed, it can be done through ghost memory permissions.\n\nVerus soundly isolates reasoning about memory bit vectors and nonlinear arithmetic from the main SMT queries, avoiding complex interactions between different kinds of reasoning in the SMT solver and speeding up the SMT queries. We discuss some of these ideas in section 3 point 3 .\n\nWhen verifying each module in a given project, Verus aggressively prunes the context sent to the SMT solver to eliminate implied but unreachable definitions.\n\nTo avoid excess instantiations of quantifiers (for all and there exists) in the SMT solver, Verus treats quantifiers more conservatively than tools like Dafny and F star .\n\nQuantifiers and SMT solving. Typical systems verification projects use for all and there exists quantifiers , for example ,to specify all elements of an array or all members of a table . Unfortunately ,SMT solving with quantifiers is undecidable in general ,so SMT solvers use heuristics to decide how to instantiate for all quantifiers and how to prove there exists quantifiers . Most large verification projects based on SMT solvers use an SMT heuristic based on “triggers,” in which the SMT solver pattern matches on expressions appearing in the formulas to determine how to instantiate quantifiers ,for example ,instantiating (for all x colon u sixty four ...f(x)...) with x equals 3 if the expression f(3) arises during the proof search . Here ,the expression f(x) is called the trigger or pattern for the quantifier .\n\nVerification tools ,including Verus ,automatically select appropriate expressions as triggers . However ,the choice of triggers has a large impact on verification performance . Prior tools ,like Dafny ,default to selecting broad triggers that match many expressions ,leading to many quantifier instantiations ;in principle this creates more opportunities for the solver to automatically complete a proof ,but in practice for large systems projects ,too many instantiations slow down the SMT solver to where it times out and fails to complete proof .\n\nTherefore ,Verus uses a more cautious policy that selects as few triggers as possible . If Verus is uncertain about best trigger ,Verus encourages user override its default selection with user’s choice . The result is more initial effort for users writing small proofs but significantly improved performance on large systems projects .",
    "page": 4,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "postcondition into verification conditions to send to an SMT solver (Z3 [46]), which automatically determines whether the formula holds for all possible function inputs.\n\nThe approach of converting proof obligations to verification conditions is standard in many verification frameworks, but the details of language design and implementation have a big effect on the efficiency of the SMT queries. We summarize some of these design choices here.\n\nVerus considers when queries are simpler and smaller by orders of magnitude to the SMT solver, which translates to significantly faster verification (Figure 9), so for a given verification problem, Verus can provide a more efficient code-prove cycle. Or conversely, given the same time budget as an existing tool, Verus can tackle larger verification problems.\n\nUnlike specification functions in Dafny [34] and F* [35], Verus Spec functions are pure, total mathematical functions with no preconditions or (direct) access to the heap [10]. Thus they can be directly encoded as SMT functions without the additional baggage of prior tools [34, 35]. As prior work explains, Rust’s type system means that explicit heap-based reasoning is rarely needed, and when it is needed, it can be done through ghost memory permissions [10].\n\nVerus soundly isolates reasoning about memory bit vectors, and nonlinear arithmetic from the main SMT queries, avoiding complex interactions between different kinds of reasoning in the SMT solver and speeding up the SMT queries. We discuss some of these ideas in §3.3.\n\nWhen verifying each module in a given project, Verus aggressively prunes the context sent to the SMT solver to eliminate implied but unreachable definitions.\n\nTo avoid excess instantiations of quantifiers (∀ and ∃) in the SMT solver, Verus treats quantifiers more conservatively than tools like Dafny [34] and F* [35] (see below).\n\nQuantifiers and SMT solving. Typical systems verification projects use ∀ and ∃ quantifiers, for example to specify all elements of an array or all members of a table. Unfortunately, SMT solving with quantifiers is undecidable in general, so SMT solvers use heuristics to decide how to instantiate ∀ quantifiers and how to prove ∃ quantifiers. Most large verification projects based on SMT solvers use an SMT heuristic based on “triggers” [49], in which the SMT solver pattern matches on expressions appearing in the formulas to determine how to instantiate quantifiers, for example, instantiating (∀ |x: u64| ...f(x)...) with x = 3 if the expression f(3) arises during the proof search. Here, the expression f(x) is called the trigger (or pattern) for the quantifier.\n\nVerification tools, including Verus, automatically select appropriate expressions as triggers. However, the choice of triggers has a large impact on verification performance. Prior tools, like Dafny, default to selecting broad triggers that match many expressions, leading to many quantifier instantiations; in principle this creates more opportunities for the solver to automatically complete a proof, but in practice for large systems projects, too many instantiations slow the SMT solver to the point where it times out and fails to complete the proof.\n\nTherefore, Verus uses a more cautious policy that selects as few triggers as possible. If Verus is uncertain about the best trigger, Verus encourages the user to override its default selection with the user’s choice. The result is more initial effort for users writing small proofs but significantly improved performance on large systems projects.",
      "textWithCitationsRemoved": "postcondition into verification conditions to send to an SMT solver, which automatically determines whether the formula holds for all possible function inputs.\n\nThe approach of converting proof obligations to verification conditions is standard in many verification frameworks, but the details of language design and implementation have a big effect on the efficiency of the SMT queries. We summarize some of these design choices here.\n\nVerus considers when queries are simpler and smaller by orders of magnitude to the SMT solver, which translates to significantly faster verification, so for a given verification problem, Verus can provide a more efficient code-prove cycle. Or conversely, given the same time budget as an existing tool, Verus can tackle larger verification problems.\n\nUnlike specification functions in Dafny and F*, Verus Spec functions are pure, total mathematical functions with no preconditions or (direct) access to the heap. Thus they can be directly encoded as SMT functions without the additional baggage of prior tools. As prior work explains, Rust’s type system means that explicit heap-based reasoning is rarely needed, and when it is needed, it can be done through ghost memory permissions.\n\nVerus soundly isolates reasoning about memory bit vectors, and nonlinear arithmetic from the main SMT queries, avoiding complex interactions between different kinds of reasoning in the SMT solver and speeding up the SMT queries. We discuss some of these ideas in §3.3.\n\nWhen verifying each module in a given project, Verus aggressively prunes the context sent to the SMT solver to eliminate implied but unreachable definitions.\n\nTo avoid excess instantiations of quantifiers (∀ and ∃) in the SMT solver, Verus treats quantifiers more conservatively than tools like Dafny and F*.\n\nQuantifiers and SMT solving. Typical systems verification projects use ∀ and ∃ quantifiers, for example to specify all elements of an array or all members of a table. Unfortunately, SMT solving with quantifiers is undecidable in general, so SMT solvers use heuristics to decide how to instantiate ∀ quantifiers and how to prove ∃ quantifiers. Most large verification projects based on SMT solvers use an SMT heuristic based on “triggers,” in which the SMT solver pattern matches on expressions appearing in the formulas to determine how to instantiate quantifiers, for example, instantiating (∀ |x: u64| ...f(x)...) with x = 3 if the expression f(3) arises during the proof search. Here, the expression f(x) is called the trigger (or pattern) for the quantifier.\n\nVerification tools, including Verus, automatically select appropriate expressions as triggers. However, the choice of triggers has a large impact on verification performance. Prior tools, like Dafny, default to selecting broad triggers that match many expressions, leading to many quantifier instantiations; in principle this creates more opportunities for the solver to automatically complete a proof, but in practice for large systems projects, too many instantiations slow the SMT solver to the point where it times out and fails to complete the proof.\n\nTherefore, Verus uses a more cautious policy that selects as few triggers as possible. If Verus is uncertain about the best trigger, Verus encourages the user to override its default selection with the user’s choice. The result is more initial effort for users writing small proofs but significantly improved performance on large systems projects."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 3,
    "mathReplacement": {
      "originalText": "postcondition into verification conditions to send to an SMT solver, which automatically determines whether the formula holds for all possible function inputs.\n\nThe approach of converting proof obligations to verification conditions is standard in many verification frameworks, but the details of language design and implementation have a big effect on the efficiency of the SMT queries. We summarize some of these design choices here.\n\nVerus considers when queries are simpler and smaller by orders of magnitude to the SMT solver, which translates to significantly faster verification, so for a given verification problem, Verus can provide a more efficient code-prove cycle. Or conversely, given the same time budget as an existing tool, Verus can tackle larger verification problems.\n\nUnlike specification functions in Dafny and F*, Verus Spec functions are pure, total mathematical functions with no preconditions or (direct) access to the heap. Thus they can be directly encoded as SMT functions without the additional baggage of prior tools. As prior work explains, Rust’s type system means that explicit heap-based reasoning is rarely needed, and when it is needed, it can be done through ghost memory permissions.\n\nVerus soundly isolates reasoning about memory bit vectors, and nonlinear arithmetic from the main SMT queries, avoiding complex interactions between different kinds of reasoning in the SMT solver and speeding up the SMT queries. We discuss some of these ideas in §3.3.\n\nWhen verifying each module in a given project, Verus aggressively prunes the context sent to the SMT solver to eliminate implied but unreachable definitions.\n\nTo avoid excess instantiations of quantifiers (∀ and ∃) in the SMT solver, Verus treats quantifiers more conservatively than tools like Dafny and F*.\n\nQuantifiers and SMT solving. Typical systems verification projects use ∀ and ∃ quantifiers, for example to specify all elements of an array or all members of a table. Unfortunately, SMT solving with quantifiers is undecidable in general, so SMT solvers use heuristics to decide how to instantiate ∀ quantifiers and how to prove ∃ quantifiers. Most large verification projects based on SMT solvers use an SMT heuristic based on “triggers,” in which the SMT solver pattern matches on expressions appearing in the formulas to determine how to instantiate quantifiers, for example, instantiating (∀ |x: u64| ...f(x)...) with x = 3 if the expression f(3) arises during the proof search. Here, the expression f(x) is called the trigger (or pattern) for the quantifier.\n\nVerification tools, including Verus, automatically select appropriate expressions as triggers. However, the choice of triggers has a large impact on verification performance. Prior tools, like Dafny, default to selecting broad triggers that match many expressions, leading to many quantifier instantiations; in principle this creates more opportunities for the solver to automatically complete a proof, but in practice for large systems projects, too many instantiations slow the SMT solver to the point where it times out and fails to complete the proof.\n\nTherefore, Verus uses a more cautious policy that selects as few triggers as possible. If Verus is uncertain about the best trigger, Verus encourages the user to override its default selection with the user’s choice. The result is more initial effort for users writing small proofs but significantly improved performance on large systems projects.",
      "wordedReplacement": "postcondition into verification conditions to send to an SMT solver, which automatically determines whether the formula holds for all possible function inputs.\n\nThe approach of converting proof obligations to verification conditions is standard in many verification frameworks, but the details of language design and implementation have a big effect on the efficiency of the SMT queries. We summarize some of these design choices here.\n\nVerus considers when queries are simpler and smaller by orders of magnitude to the SMT solver, which translates to significantly faster verification, so for a given verification problem, Verus can provide a more efficient code-prove cycle. Or conversely, given the same time budget as an existing tool, Verus can tackle larger verification problems.\n\nUnlike specification functions in Dafny and F star , Verus Spec functions are pure, total mathematical functions with no preconditions or direct access to the heap. Thus they can be directly encoded as SMT functions without the additional baggage of prior tools. As prior work explains, Rust’s type system means that explicit heap-based reasoning is rarely needed, and when it is needed, it can be done through ghost memory permissions.\n\nVerus soundly isolates reasoning about memory bit vectors and nonlinear arithmetic from the main SMT queries, avoiding complex interactions between different kinds of reasoning in the SMT solver and speeding up the SMT queries. We discuss some of these ideas in section 3 point 3 .\n\nWhen verifying each module in a given project, Verus aggressively prunes the context sent to the SMT solver to eliminate implied but unreachable definitions.\n\nTo avoid excess instantiations of quantifiers (for all and there exists) in the SMT solver, Verus treats quantifiers more conservatively than tools like Dafny and F star .\n\nQuantifiers and SMT solving. Typical systems verification projects use for all and there exists quantifiers , for example ,to specify all elements of an array or all members of a table . Unfortunately ,SMT solving with quantifiers is undecidable in general ,so SMT solvers use heuristics to decide how to instantiate for all quantifiers and how to prove there exists quantifiers . Most large verification projects based on SMT solvers use an SMT heuristic based on “triggers,” in which the SMT solver pattern matches on expressions appearing in the formulas to determine how to instantiate quantifiers ,for example ,instantiating (for all x colon u sixty four ...f(x)...) with x equals 3 if the expression f(3) arises during the proof search . Here ,the expression f(x) is called the trigger or pattern for the quantifier .\n\nVerification tools ,including Verus ,automatically select appropriate expressions as triggers . However ,the choice of triggers has a large impact on verification performance . Prior tools ,like Dafny ,default to selecting broad triggers that match many expressions ,leading to many quantifier instantiations ;in principle this creates more opportunities for the solver to automatically complete a proof ,but in practice for large systems projects ,too many instantiations slow down the SMT solver to where it times out and fails to complete proof .\n\nTherefore ,Verus uses a more cautious policy that selects as few triggers as possible . If Verus is uncertain about best trigger ,Verus encourages user override its default selection with user’s choice . The result is more initial effort for users writing small proofs but significantly improved performance on large systems projects ."
    },
    "optimizedMath": true
  },
  {
    "type": "code_or_algorithm",
    "content": "Figure 2  code explanation:\nThis code defines a generic `LinkedList` structure in Rust, which uses a `Node` to store elements. The `LinkedList` has a method `pop` that removes and returns the first element of the list. The `pop` function has a precondition that the list must be non-empty before it is called. It ensures that the returned result is the first element of the list and that this element is removed from the list. The function modifies the list by updating the head to the next node after removing the first element.",
    "page": 4,
    "label": {
      "labelType": "Figure",
      "labelNumber": "2",
      "panelNumber": "unlabeled"
    },
    "title": "LinkedList Pop Method in Rust",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]3.2 Selective Use of EPR for Full Automation[break0.7]",
    "page": 4,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Motivation. Several prior works explicitly restrict the expressivity of system properties and implementations in order to obtain powerful proof automation. The developer only needed to provide a little proof support, leading to dramatically new proof-to-code ratios, for example, Hyperkernel reports zero point zero three to one. The Ivy verification tool — built on EPR (effectively propositionally logic) — demonstrates that despite reduced expressivity, diverse system designs and implementations can be encoded, yielding fully automated proofs and even enabling invariant inference.\n\nWhile EPR leads to impressive proof automation, some system components can be difficult to capture in EPR. EPR’s first-order logic admits only Boolean operators, quantifiers, and uninterpreted functions. For example, EPR can express the property that a node sends at most one message per epoch as for all m one and m two. sendert of m one equals sendert of m two and epocht of m one equals epocht of m two implies m one equals m two. EPR cannot directly express many common concepts, such as sequences or arithmetic; for example, epocht of m two equals one plus epocht of m one is disallowed. Instead, natural numbers are typically abstracted as a totally ordered set without arithmetic operations. EPR further requires that functions and quantifier-alternations are acyclic; for example, the sender function above that maps messages to nodes precludes both a function from nodes to messages and a property like for all n,e,e less than e max implies there exists m such that senderm of n equals n and epocht of m equals e.",
    "page": 4,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Motivation. Several prior works [1, 5–8] explicitly restrict the expressivity of system properties and implementations in order to obtain powerful proof automation. The developer only needed to provide a little proof support, leading to dramatically new proof-to-code ratios, e.g., Hyperkernel reports 0.03:1 [4]. The Ivy verification tool [7, 8] — built on EPR (effectively propositionally logic) [17] — demonstrates that despite reduced expressivity, diverse system designs and implementations can be encoded [9, 18, 50], yielding fully automated proofs and even enabling invariant inference [19–22].\n\nWhile EPR leads to impressive proof automation, some system components can be difficult to capture in EPR. EPR’s first-order logic admits only Boolean operators, quantifiers, and uninterpreted functions. For example, EPR can express the property that a node sends at most one message per epoch as ∀m1,m2. sendert(m1) = sendert(m2) ∧ epocht(m1) = epocht(m2) ⇒ m1 = m2. EPR cannot directly express many common concepts, such as sequences or arithmetic; e.g., epocht(m2) = 1 + epocht(m1) is disallowed. Instead, natural numbers are typically abstracted as a totally ordered set without arithmetic operations. EPR further requires that functions and quantifier-alternations are acyclic [18]; e.g., the sender function above that maps messages to nodes precludes both a function from nodes to messages and a property like ∀n,e,e < emax ⇒ ∃m. senderm(n) = n ∧ epocht(m) = e.",
      "textWithCitationsRemoved": "Motivation. Several prior works explicitly restrict the expressivity of system properties and implementations in order to obtain powerful proof automation. The developer only needed to provide a little proof support, leading to dramatically new proof-to-code ratios, e.g., Hyperkernel reports 0.03:1. The Ivy verification tool — built on EPR (effectively propositionally logic) — demonstrates that despite reduced expressivity, diverse system designs and implementations can be encoded, yielding fully automated proofs and even enabling invariant inference.\n\nWhile EPR leads to impressive proof automation, some system components can be difficult to capture in EPR. EPR’s first-order logic admits only Boolean operators, quantifiers, and uninterpreted functions. For example, EPR can express the property that a node sends at most one message per epoch as ∀m1,m2. sendert(m1) = sendert(m2) ∧ epocht(m1) = epocht(m2) ⇒ m1 = m2. EPR cannot directly express many common concepts, such as sequences or arithmetic; e.g., epocht(m2) = 1 + epocht(m1) is disallowed. Instead, natural numbers are typically abstracted as a totally ordered set without arithmetic operations. EPR further requires that functions and quantifier-alternations are acyclic; e.g., the sender function above that maps messages to nodes precludes both a function from nodes to messages and a property like ∀n,e,e < emax ⇒ ∃m. senderm(n) = n ∧ epocht(m) = e."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 3,
    "mathReplacement": {
      "originalText": "Motivation. Several prior works explicitly restrict the expressivity of system properties and implementations in order to obtain powerful proof automation. The developer only needed to provide a little proof support, leading to dramatically new proof-to-code ratios, e.g., Hyperkernel reports 0.03:1. The Ivy verification tool — built on EPR (effectively propositionally logic) — demonstrates that despite reduced expressivity, diverse system designs and implementations can be encoded, yielding fully automated proofs and even enabling invariant inference.\n\nWhile EPR leads to impressive proof automation, some system components can be difficult to capture in EPR. EPR’s first-order logic admits only Boolean operators, quantifiers, and uninterpreted functions. For example, EPR can express the property that a node sends at most one message per epoch as ∀m1,m2. sendert(m1) = sendert(m2) ∧ epocht(m1) = epocht(m2) ⇒ m1 = m2. EPR cannot directly express many common concepts, such as sequences or arithmetic; e.g., epocht(m2) = 1 + epocht(m1) is disallowed. Instead, natural numbers are typically abstracted as a totally ordered set without arithmetic operations. EPR further requires that functions and quantifier-alternations are acyclic; e.g., the sender function above that maps messages to nodes precludes both a function from nodes to messages and a property like ∀n,e,e < emax ⇒ ∃m. senderm(n) = n ∧ epocht(m) = e.",
      "wordedReplacement": "Motivation. Several prior works explicitly restrict the expressivity of system properties and implementations in order to obtain powerful proof automation. The developer only needed to provide a little proof support, leading to dramatically new proof-to-code ratios, for example, Hyperkernel reports zero point zero three to one. The Ivy verification tool — built on EPR (effectively propositionally logic) — demonstrates that despite reduced expressivity, diverse system designs and implementations can be encoded, yielding fully automated proofs and even enabling invariant inference.\n\nWhile EPR leads to impressive proof automation, some system components can be difficult to capture in EPR. EPR’s first-order logic admits only Boolean operators, quantifiers, and uninterpreted functions. For example, EPR can express the property that a node sends at most one message per epoch as for all m one and m two. sendert of m one equals sendert of m two and epocht of m one equals epocht of m two implies m one equals m two. EPR cannot directly express many common concepts, such as sequences or arithmetic; for example, epocht of m two equals one plus epocht of m one is disallowed. Instead, natural numbers are typically abstracted as a totally ordered set without arithmetic operations. EPR further requires that functions and quantifier-alternations are acyclic; for example, the sender function above that maps messages to nodes precludes both a function from nodes to messages and a property like for all n,e,e less than e max implies there exists m such that senderm of n equals n and epocht of m equals e."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "In Ivy in order to obtain the benefits of EPR proof automation the entire system needs to be expressed in EPR, including elements for which EPR is awkward. In contrast, using a general-purpose tool (like Dafny or F*) avoids this awkwardness but does not offer the same level of automation, even for parts of the proof where better automation may be possible with EPR.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Our Approach.[break0.7]",
    "page": 5,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In Verus we obtain the best of both worlds by soundly integrating EPR proofs with Verus’s general-purpose semi-automation; we use the latter for most parts of the system, and apply EPR to those proofs it best fits. The main challenge in enabling seamless integration is defining and separating the EPR and non-EPR parts, and then composing them without adding trusted components. Overcoming this challenge is aided by Verus’s clean SMT encoding, its constructs for partitioning proofs, and its ability to control automation scoping.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To use EPR in Verus, a developer (a) defines a protocol or a data structure without restrictions, (b) abstracts the protocol or data structure into EPR, (c) uses Verus’s integrated EPR solver for automatic, predictable proofs over the abstraction, and (d) exports those proof results to the original definition where they support postconditions and lemmas.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The connection between (a) and (b) is checked using Verus’s default-mode automation, and in our experience is easily discharged. Step (c) typically involves a set of complex invariants that would have required significant manual proof in default mode, but which Verus’s EPR mode resolves automatically. The connection (d) back to the original proof obligations for (a) is again easily checked in default mode.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We illustrate this process on the delegation map data structure from one of our case studies—the Verus port of IronKV. Originally written in Dafny for IronFleet, IronKV is a distributed key-value store where each node maintains a delegation map to associate each possible key to the host responsible for it. For efficiency, the domain is stored as a compact list of pivots that represent the key ranges. The delegation map supports three operations:",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We illustrate this process on the delegation map data structure from one of our case studies—the Verus port of IronKV (§4.2.1). Originally written in Dafny for IronFleet [1], IronKV is a distributed key-value store where each node maintains a delegation map to associate each possible key to the host responsible for it. For efficiency, the domain is stored as a compact list of pivots that represent the key ranges. The delegation map supports three operations:",
      "textWithCitationsRemoved": "We illustrate this process on the delegation map data structure from one of our case studies—the Verus port of IronKV. Originally written in Dafny for IronFleet, IronKV is a distributed key-value store where each node maintains a delegation map to associate each possible key to the host responsible for it. For efficiency, the domain is stored as a compact list of pivots that represent the key ranges. The delegation map supports three operations:"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Figure three illustrates the components of the delegation map and its EPR proof. First, (a) our DelegationMap data structure implements the new, get, and set operations in regular Rust code with pre- and postconditions expressed in an unrestricted manner, similar to the Dafny original. Our (b) DelegationMapEPRModel abstracts the data structure and its operations into EPR. We then (c) write an inductive invariant in EPR—DelegationMapEPRProof—to automatically prove an EPR version of the postconditions of each operation. Finally, we (d) use these proofs to discharge the implementation’s proof obligations for new, get, and set.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "Figure 3 illustrates the components of the delegation map and its EPR proof. First, (a) our DelegationMap data structure implements the new, get, and set operations in regular Rust code with pre- and postconditions expressed in an unrestricted manner, similar to the Dafny original. Our (b) DelegationMapEPRModel abstracts the data structure and its operations into EPR. We then (c) write an inductive invariant in EPR—DelegationMapEPRProof—to automatically prove an EPR version of the postconditions of each operation. Finally, we (d) use these proofs to discharge the implementation’s proof obligations for new, get, and set.",
      "wordedReplacement": "Figure three illustrates the components of the delegation map and its EPR proof. First, (a) our DelegationMap data structure implements the new, get, and set operations in regular Rust code with pre- and postconditions expressed in an unrestricted manner, similar to the Dafny original. Our (b) DelegationMapEPRModel abstracts the data structure and its operations into EPR. We then (c) write an inductive invariant in EPR—DelegationMapEPRProof—to automatically prove an EPR version of the postconditions of each operation. Finally, we (d) use these proofs to discharge the implementation’s proof obligations for new, get, and set."
    },
    "optimizedMath": true
  },
  {
    "type": "code_or_algorithm",
    "content": "Code   code explanation:\nThis code describes operations for managing a delegation map in a distributed key-value store. The operations include:\n\n1. **new**: Initializes a map where all keys are assigned to a single host.\n2. **set**: Assigns a range of keys to a specified host.\n3. **get**: Retrieves the host responsible for a specific key.\n\nThese operations are used to efficiently manage key-host mappings in systems like IronKV.",
    "page": 5,
    "label": {
      "labelType": "Code",
      "labelNumber": "unlabeled",
      "panelNumber": "unlabeled"
    },
    "title": "Delegation Map Operations",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 3  summary:\nThis figure illustrates the process of verifying the IronKV Delegation Map using EPR mode. It shows a flow from the concrete implementation of the DelegationMap (a) to its abstraction in EPR (b), and then to the automated proof of invariants (c). These proofs are used to verify the correctness of the implementation (d). The diagram highlights the steps involved in abstracting the data structure and operations into EPR, writing inductive invariants, and using these proofs to discharge the implementation's proof obligations. This process allows for a fully automated verification of the Delegation Map's correctness, integrating EPR proofs with Verus's general-purpose verification.",
    "page": 5,
    "label": {
      "labelType": "Figure",
      "labelNumber": "3",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The implementation of the delegation map uses natural numbers for the keys. To express the proof in EPR, we abstract the keys as a totally ordered set. Verus trivially proves the soundness of this abstraction, allowing the implementation to invoke the EPR results.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The efficient list-of-pivots implementation leads to many tricky corner cases, resulting in an extensive proof in the original Dafny version. Our initial default-mode Verus proof was also extensive; for example, the set operation required approximately 300 lines of proof (mostly case splitting and assertions then instantiate quantifiers) and took several days of developer effort. However, by abstracting both keys as a totally ordered set, proofs can be expressed in Verus’s EPR mode, yielding much greater proof automation. The developer still writes an inductive invariant, but the invariant is checked completely automatically. However, unlike in Ivy, the implementation’s pre- and post-conditions are expressed outside of EPR, seamlessly integrating with the rest of IronKV.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "The efficient list-of-pivots implementation leads to many tricky corner cases, resulting in an extensive proof in the original Dafny version. Our initial default-mode Verus proof was also extensive; e.g., the set operation required ~ 300 lines of proof (mostly case splitting and assertions then instantiate quantifiers) and took several days of developer effort. However, by abstracting both keys as a totally ordered set, proofs can be expressed in Verus’s EPR mode, yielding much greater proof automation. The developer still writes an inductive invariant, but the invariant is checked completely automatically, similar to Ivy [7]. However, unlike in Ivy, the implementation’s pre- and post-conditions are expressed outside of EPR, seamlessly integrating with the rest of IronKV.",
      "textWithCitationsRemoved": "The efficient list-of-pivots implementation leads to many tricky corner cases, resulting in an extensive proof in the original Dafny version. Our initial default-mode Verus proof was also extensive; e.g., the set operation required ~ 300 lines of proof (mostly case splitting and assertions then instantiate quantifiers) and took several days of developer effort. However, by abstracting both keys as a totally ordered set, proofs can be expressed in Verus’s EPR mode, yielding much greater proof automation. The developer still writes an inductive invariant, but the invariant is checked completely automatically. However, unlike in Ivy, the implementation’s pre- and post-conditions are expressed outside of EPR, seamlessly integrating with the rest of IronKV."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "The efficient list-of-pivots implementation leads to many tricky corner cases, resulting in an extensive proof in the original Dafny version. Our initial default-mode Verus proof was also extensive; e.g., the set operation required ~ 300 lines of proof (mostly case splitting and assertions then instantiate quantifiers) and took several days of developer effort. However, by abstracting both keys as a totally ordered set, proofs can be expressed in Verus’s EPR mode, yielding much greater proof automation. The developer still writes an inductive invariant, but the invariant is checked completely automatically. However, unlike in Ivy, the implementation’s pre- and post-conditions are expressed outside of EPR, seamlessly integrating with the rest of IronKV.",
      "wordedReplacement": "The efficient list-of-pivots implementation leads to many tricky corner cases, resulting in an extensive proof in the original Dafny version. Our initial default-mode Verus proof was also extensive; for example, the set operation required approximately 300 lines of proof (mostly case splitting and assertions then instantiate quantifiers) and took several days of developer effort. However, by abstracting both keys as a totally ordered set, proofs can be expressed in Verus’s EPR mode, yielding much greater proof automation. The developer still writes an inductive invariant, but the invariant is checked completely automatically. However, unlike in Ivy, the implementation’s pre- and post-conditions are expressed outside of EPR, seamlessly integrating with the rest of IronKV."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "At a technical level: The Verus developer marks individual modules with the hash bracket epr underscore mode bracket attribute, instructing Verus to check that the module’s proof obligations are all within EPR. Verus confirms that structs have private fields so they act as uninterpreted types. It also checks acyclicity of the quantifier-alternation graph. Finally, Verus enables Z3’s model-based quantifier instantiation, a complete (and often fast) decision procedure for EPR. Due to technicalities of Verus’s SMT encoding of polymorphic types, epr underscore mode queries are not strictly in EPR, but we have not yet observed any correct proofs that fail to verify automatically.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "At a technical level: The Verus developer marks individual modules with the #[epr_mode] attribute, instructing Verus to check that the module’s proof obligations are all within EPR. Verus confirms that structs have private fields so they act as uninterpreted types. It also checks acyclicity of the quantifier-alternation graph [18]. Finally, Verus enables Z3’s model-based quantifier instantiation, a complete (and often fast) decision procedure for EPR. Due to technicalities of Verus’s SMT encoding of polymorphic types, epr_mode queries are not strictly in EPR, but we have not yet observed any (correct) proofs that fail to verify automatically.",
      "textWithCitationsRemoved": "At a technical level: The Verus developer marks individual modules with the #[epr_mode] attribute, instructing Verus to check that the module’s proof obligations are all within EPR. Verus confirms that structs have private fields so they act as uninterpreted types. It also checks acyclicity of the quantifier-alternation graph. Finally, Verus enables Z3’s model-based quantifier instantiation, a complete (and often fast) decision procedure for EPR. Due to technicalities of Verus’s SMT encoding of polymorphic types, epr_mode queries are not strictly in EPR, but we have not yet observed any (correct) proofs that fail to verify automatically."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "At a technical level: The Verus developer marks individual modules with the #[epr_mode] attribute, instructing Verus to check that the module’s proof obligations are all within EPR. Verus confirms that structs have private fields so they act as uninterpreted types. It also checks acyclicity of the quantifier-alternation graph. Finally, Verus enables Z3’s model-based quantifier instantiation, a complete (and often fast) decision procedure for EPR. Due to technicalities of Verus’s SMT encoding of polymorphic types, epr_mode queries are not strictly in EPR, but we have not yet observed any (correct) proofs that fail to verify automatically.",
      "wordedReplacement": "At a technical level: The Verus developer marks individual modules with the hash bracket epr underscore mode bracket attribute, instructing Verus to check that the module’s proof obligations are all within EPR. Verus confirms that structs have private fields so they act as uninterpreted types. It also checks acyclicity of the quantifier-alternation graph. Finally, Verus enables Z3’s model-based quantifier instantiation, a complete (and often fast) decision procedure for EPR. Due to technicalities of Verus’s SMT encoding of polymorphic types, epr underscore mode queries are not strictly in EPR, but we have not yet observed any correct proofs that fail to verify automatically."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "Our integration of EPR reasoning with a general-purpose program verifier is enhanced in part by Verus’s emphasis on query economy. Most program verifiers produce complex SMT queries even for simple programs, immediately pushing them beyond EPR. In contrast, epr_mode’s SMT encoding is quite close to Verus’s default mode.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Our integration of EPR reasoning with a general-purpose program verifier is enhanced in part by Verus’s emphasis on query economy (§3.1). Most program verifiers [11, 34, 35] produce complex SMT queries even for simple programs, immediately pushing them beyond EPR. In contrast, epr_mode’s SMT encoding is quite close to Verus’s default mode.",
      "textWithCitationsRemoved": "Our integration of EPR reasoning with a general-purpose program verifier is enhanced in part by Verus’s emphasis on query economy. Most program verifiers produce complex SMT queries even for simple programs, immediately pushing them beyond EPR. In contrast, epr_mode’s SMT encoding is quite close to Verus’s default mode."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Summarizing, for modules that fit in EPR, Verus provides full automation, which prior work shows reduces developer effort by eliminating hundreds of lines of difficult proofs. Since Verus soundly embeds EPR in a general-purpose verifier, developing in a restricted logic is no longer an all-or-nothing affair.",
    "page": 5,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]3.3 Custom Proof Automation for System Idioms[break0.7]",
    "page": 6,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Motivation. To gain performance, systems employ various “tricks” that are challenging to automate using generic tools. Our Approach. Rather than feed every verification problem to a generalized SMT solver, Verus includes various (trusted) automation tools, intuitively exposed to developers. In each case, Verus checks the developer’s claim fully automatically using custom automation; the SMT encoding then simply assumes it is true.",
    "page": 6,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Nonlinear Arithmetic Reasoning[break0.7]",
    "page": 6,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Systems often employ nonlinear arithmetic, i.e., formulas with terms like x times x or x squared that combine variables using operations beyond addition and subtraction. Verus automates such reasoning in two ways.",
    "page": 6,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Systems often employ nonlinear arithmetic, i.e., formulas with terms like \\(x \\times x\\) or \\(x^2\\) that combine variables using operations beyond addition and subtraction. Such terms might relate adjacent page table entries (\\S4.2.3) or indicate the bucket to use when allocating memory (\\S4.2.4). Verus automates such reasoning in two ways.",
      "textWithCitationsRemoved": "Systems often employ nonlinear arithmetic, i.e., formulas with terms like \\(x \\times x\\) or \\(x^2\\) that combine variables using operations beyond addition and subtraction. Verus automates such reasoning in two ways."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 2,
    "mathReplacement": {
      "originalText": "Systems often employ nonlinear arithmetic, i.e., formulas with terms like \\(x \\times x\\) or \\(x^2\\) that combine variables using operations beyond addition and subtraction. Verus automates such reasoning in two ways.",
      "wordedReplacement": "Systems often employ nonlinear arithmetic, i.e., formulas with terms like x times x or x squared that combine variables using operations beyond addition and subtraction. Verus automates such reasoning in two ways."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "First, while nonlinear arithmetic is generally undecidable (meaning no algorithm can solve all such formulas), subclasses are both decidable and fast in practice. Verus supports fully automated proofs of integer ring “congruence relations”—equalities built from plus, minus, times, and exponentiation—via annotation:",
    "page": 6,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "First, while nonlinear arithmetic is generally undecidable (meaning no algorithm can solve all such formulas), subclasses are both decidable and fast in practice. Inspired by others [52, 53], Verus supports fully automated proofs of integer ring “congruence relations”—equalities built from +, −, ×, and exponentiation—via annotation:",
      "textWithCitationsRemoved": "First, while nonlinear arithmetic is generally undecidable (meaning no algorithm can solve all such formulas), subclasses are both decidable and fast in practice. Verus supports fully automated proofs of integer ring “congruence relations”—equalities built from +, −, ×, and exponentiation—via annotation:"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 3,
    "mathReplacement": {
      "originalText": "First, while nonlinear arithmetic is generally undecidable (meaning no algorithm can solve all such formulas), subclasses are both decidable and fast in practice. Verus supports fully automated proofs of integer ring “congruence relations”—equalities built from +, −, ×, and exponentiation—via annotation:",
      "wordedReplacement": "First, while nonlinear arithmetic is generally undecidable (meaning no algorithm can solve all such formulas), subclasses are both decidable and fast in practice. Verus supports fully automated proofs of integer ring “congruence relations”—equalities built from plus, minus, times, and exponentiation—via annotation:"
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "Second, for problems outside decidable fragments, we enable the SMT solver’s nonlinear heuristics in a controlled environment where they are more likely to succeed consistently. Unlike normal Verus assertions, nonlinear assertions generate an isolated query without implicit context. In the example below, even though we know from context that y is greater than 2, this fact is not automatically available in the assert and must be provided as the premise of the implication. The extra developer burden provides greater predictability:",
    "page": 6,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 2,
    "mathReplacement": {
      "originalText": "Second, for problems outside decidable fragments, we enable the SMT solver’s nonlinear heuristics in a controlled environment where they are more likely to succeed consistently. Unlike normal Verus assertions, nonlinear assertions generate an isolated query without implicit context. In the example below, even though we know from context that \\(y > 2\\), this fact is not automatically available in the assert and must be provided as the premise of the implication. The extra developer burden provides greater predictability:",
      "wordedReplacement": "Second, for problems outside decidable fragments, we enable the SMT solver’s nonlinear heuristics in a controlled environment where they are more likely to succeed consistently. Unlike normal Verus assertions, nonlinear assertions generate an isolated query without implicit context. In the example below, even though we know from context that y is greater than 2, this fact is not automatically available in the assert and must be provided as the premise of the implication. The extra developer burden provides greater predictability:"
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "The code above automatically generates relevant proof obligations, such as the fact that agreement_invariant is inductive; in this case Verus’s SMT solver discharges them without additional proof work. Once these proofs succeed, Verus generates the relevant resource, the update operation (update), and the proof result (agreement). The result is the agreement protocol interface (bottom part).",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "code_or_algorithm",
    "content": "Code   code explanation:\nThis code defines a function named `f6` that takes two unsigned 64-bit integers, `x` and `a`, as inputs. The function requires that `a` is greater than 2. It asserts a mathematical condition involving nonlinear arithmetic: if `y` is greater than or equal to 2, then the expression `(a + 1) * 2` should be greater than or equal to `(a + a + 1) * 2`. The assertion is verified using nonlinear arithmetic reasoning, which is part of the Verus system's approach to handling such problems.",
    "page": 6,
    "label": {
      "labelType": "Code",
      "labelNumber": "unlabeled",
      "panelNumber": "unlabeled"
    },
    "title": "Nonlinear Arithmetic Assertion Function",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 2
  },
  {
    "type": "code_or_algorithm",
    "content": "Figure 4  code explanation:\nThe code defines a system called VerusSync, which is designed to maintain agreement between two integer fields, `a` and `b`. It includes an initialization function that sets both fields to the same value and an update function that updates both fields to a new value. The code ensures that the two fields remain equal through an invariant property. Additionally, an agreement protocol is defined, which includes functions for tokenizing values into pairs and updating them while maintaining their agreement. The protocol ensures that the values of the pairs remain consistent and equal.",
    "page": 7,
    "label": {
      "labelType": "Figure",
      "labelNumber": "4",
      "panelNumber": "unlabeled"
    },
    "title": "VerusSync and Agreement Protocol",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "As a simplified example, consider a program with two objects and a developer who wishes to maintain the invariant that the objects both store the same value. Without verification, the developer could informally enforce this invariant by writing code that follows a protocol in which an update can only be performed when both objects are held by the same thread (as formalized in Figure 4 (bottom)). The protocol intuitively enforces the invariant, but how can we prove it? During times when the objects are owned by disjoint threads, “who” maintains the invariant? The resource algebra solves this problem, giving us a way to determine sound “update” operations for a given invariant.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 4  summary:\nThis figure shows a code example demonstrating the VerusSync system, which ensures two integer fields, `a` and `b`, remain in agreement. The code includes an initialization function to set both fields to the same value and an update function to maintain their equality. The invariant property ensures the fields remain equal. Additionally, an agreement protocol is defined, which includes functions for tokenizing values into pairs and updating them while maintaining their agreement. This protocol ensures the values of the pairs remain consistent and equal. The figure illustrates how VerusSync automatically generates proof obligations, which are discharged by Verus’s SMT solver without additional proof work, ensuring the agreement protocol interface is correctly implemented.",
    "page": 7,
    "label": {
      "labelType": "Figure",
      "labelNumber": "4",
      "panelNumber": "unlabeled"
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In fact, this idea has been employed before; IronSync shows how to do it with the ownership type system of Linear Dafny, and this in turn inspired Verus’s ownership-based ghost types. However, the monoid-based mathematical formalism behind resource algebras is quite technical; it takes considerable expertise to interpret monoids in the context of a concurrent system.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Rust’s ownership types are a natural representation for ownership of resource algebra resources. In fact, this idea has been employed before; IronSync [29] shows how to do it with the ownership type system of Linear Dafny [16], and this in turn inspired Verus’s ownership-based ghost types [10]. However, the monoid-based mathematical formalism behind resource algebras is quite technical; it takes considerable expertise to interpret monoids in the context of a concurrent system. Thus, deploying this idea in practical systems verification requires a second big idea to streamline the process.",
      "textWithCitationsRemoved": "Rust’s ownership types are a natural representation for ownership of resource algebra resources. In fact, this idea has been employed before; IronSync shows how to do it with the ownership type system of Linear Dafny, and this in turn inspired Verus’s ownership-based ghost types. However, the monoid-based mathematical formalism behind resource algebras is quite technical; it takes considerable expertise to interpret monoids in the context of a concurrent system. Thus, deploying this idea in practical systems verification requires a second big idea to streamline the process."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 2,
    "mathReplacement": {
      "originalText": "In fact, this idea has been employed before; IronSync shows how to do it with the ownership type system of Linear Dafny, and this in turn inspired Verus’s ownership-based ghost types. However, the monoid-based mathematical formalism behind resource algebras is quite technical; it takes considerable expertise to interpret monoids in the context of a concurrent system.",
      "wordedReplacement": "In fact, this idea has been employed before; IronSync shows how to do it with the ownership type system of Linear Dafny, and this in turn inspired Verus’s ownership-based ghost types. However, the monoid-based mathematical formalism behind resource algebras is quite technical; it takes considerable expertise to interpret monoids in the context of a concurrent system."
    },
    "optimizedMath": true
  },
  {
    "type": "heading",
    "content": "[break0.7]Idea II: A Specification Language for Transitions[break0.7]",
    "page": 7,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To enable a practical, streamlined process for constructing the complex ghost state needed for sophisticated concurrent algorithms, we introduce a novel framework called VerusSync. To design VerusSync, we first observe that a resource algebra update, which exchanges one set of resources for another, is fundamentally a transition. We posit that state transitions are an intuitive basis for reasoning about a system. However, in the canonical resource algebra formulation, a developer derives these transitions by a set of rules based on the compositional monoid structure of a resource algebra, which is less intuitive as a basis for system reasoning.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "To enable a practical, streamlined process for constructing the complex ghost state needed for sophisticated concurrent algorithms, we introduce a novel framework called VerusSync. To design VerusSync, we first observe that a resource algebra update, which exchanges one set of resources for another, is fundamentally a transition. We posit that state transitions are an intuitive basis for reasoning about a system. However, in the canonical resource algebra formulation, a developer derives these transitions by a set of rules based on the compositional monoid structure of a resource algebra, which is less intuitive as a basis for system reasoning.",
      "wordedReplacement": "To enable a practical, streamlined process for constructing the complex ghost state needed for sophisticated concurrent algorithms, we introduce a novel framework called VerusSync. To design VerusSync, we first observe that a resource algebra update, which exchanges one set of resources for another, is fundamentally a transition. We posit that state transitions are an intuitive basis for reasoning about a system. However, in the canonical resource algebra formulation, a developer derives these transitions by a set of rules based on the compositional monoid structure of a resource algebra, which is less intuitive as a basis for system reasoning."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "In VerusSync, therefore, we make transitions the central object for reasoning. In a VerusSync system, the developer specifies transitions up front, and thus VerusSync has special syntax for transitions, based on the elegant state-transition syntax in Ivy, which has been widely used to verify concurrent distributed systems, a close relative of concurrent multi-threaded systems. As with Ivy, VerusSync transitions are described by enabling conditions (specifying when a transition is allowed) and state updates (see Figure 4, top). The unique part of VerusSync is its special “sharded” update commands, illustrated below.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "In VerusSync, therefore, we make transitions the central object for reasoning. In a VerusSync system, the developer specifies transitions up front, and thus VerusSync has special syntax for transitions, based on the elegant state-transition syntax in Ivy [7, 8], which has been widely used to verify concurrent distributed systems, a close relative of concurrent multi-threaded systems. As with Ivy, VerusSync transitions are described by enabling conditions (specifying when a transition is allowed) and state updates (see Figure 4, top). The unique part of VerusSync is its special “sharded” update commands, illustrated below.",
      "textWithCitationsRemoved": "In VerusSync, therefore, we make transitions the central object for reasoning. In a VerusSync system, the developer specifies transitions up front, and thus VerusSync has special syntax for transitions, based on the elegant state-transition syntax in Ivy, which has been widely used to verify concurrent distributed systems, a close relative of concurrent multi-threaded systems. As with Ivy, VerusSync transitions are described by enabling conditions (specifying when a transition is allowed) and state updates (see Figure 4, top). The unique part of VerusSync is its special “sharded” update commands, illustrated below."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In showing that a VerusSync system is well-formed, the key proof obligations are safety conditions, which the developer proves by supplying an inductive invariant. Supplying inductive invariants may still be nontrivial, but it is a widely understood process that allows developers to draw new inferences with loop invariants and distributed system invariants. Because of this, our experience has shown us that resources are easier to specify and prove correct this way than via monoid composition. However, VerusSync still appeals to the same underlying theory behind resource algebras; our metatheory shows that a well-formed VerusSync system (that is, one satisfying the inductiveness conditions) always corresponds to a resource algebra with the necessary properties.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "In showing that a VerusSync system is well-formed, the key proof obligations are safety conditions, which the developer proves by supplying an inductive invariant. Supplying inductive invariants may still be nontrivial, but it is a widely understood process that allows developers to draw new inferences with loop invariants and distributed system invariants. Because of this, our experience has shown us that resources are easier to specify and prove correct this way than via monoid composition. However, VerusSync still appeals to the same underlying theory behind resource algebras; our metatheory shows that a well-formed VerusSync system (i.e., one satisfying the inductiveness conditions) always corresponds to a resource algebra with the necessary properties.",
      "wordedReplacement": "In showing that a VerusSync system is well-formed, the key proof obligations are safety conditions, which the developer proves by supplying an inductive invariant. Supplying inductive invariants may still be nontrivial, but it is a widely understood process that allows developers to draw new inferences with loop invariants and distributed system invariants. Because of this, our experience has shown us that resources are easier to specify and prove correct this way than via monoid composition. However, VerusSync still appeals to the same underlying theory behind resource algebras; our metatheory shows that a well-formed VerusSync system (that is, one satisfying the inductiveness conditions) always corresponds to a resource algebra with the necessary properties."
    },
    "optimizedMath": true
  },
  {
    "type": "heading",
    "content": "[break0.7]VerusSync In Action.[break0.7]",
    "page": 7,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In VerusSync, the developer first constructs a state comprised of fields, each labeled with a sharding strategy defining how the field relates to objects/shards manipulated in the code. For example, a variable field is represented by a single shard; a map field is represented by one shard for every key-value entry in the map.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Next, the developer defines the protocol as VerusSync transitions. Each “update” operation has one meaning for the aggregate state and a corresponding meaning as an operation on shards. For example, the add keyword adds a key-value pair to a state’s map field and correspondingly creates a shard containing the pair. Similarly, remove means “remove a key-value pair” and “consume a shard”.",
    "page": 7,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]NR Queue.[break0.7]",
    "page": 8,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "At the core of our NR case study is a ring buffer that tracks three pieces of state in shared memory:\n\n• a buffer for storing message entries,\n• a tail pointer where the next message goes, and\n• a per-thread head pointer, indicating where each thread should read the next message.\n\nThere is a complex, multi-step protocol for reading and processing messages from the queue. This protocol is implemented by a thread called the executor thread. As the queue operates, no one thread ever simultaneously owns all the pieces of state above, as they are accessed and updated concurrently. Even so, we maintain complex invariants, for example relating an executor thread’s internal state to its head pointers, or relating the head and tail pointers to non-empty buffer entries.\n\nWe model this protocol as a VerusSync protocol with fields representing the pieces of state, and we distribute the resulting shards across the threads. The ring buffer’s fields are shared with different strategies.\n\n• The tail field marks the next empty space. Its value is represented by a single shard that a thread must own to read or modify the field. The ghost shard is associated with a particular physical memory word accessed atomically, here via compare-and-swap.\n• The buffer size field is constant: all threads agree on \"read\" its value at all times.\n• The local versions field contains per-thread head-pointers into the queue. It is represented by a map where each entry is an owned shared, each associated with a different atomically-accessed memory word.\n• The executor field describes the intermediate state of each executor thread within its multi-step protocol.\n\nIn NR, an executor thread pops operations off the queue and processes them. The thread selects a range to read, reads each buffer entry in that range, and finally updates the atomic field corresponding to an entry of last version to point to the end of this range. Figure 5 shows this final step of the protocol, as expressed in VerusSync. Verus then generates appropriate owned ghost shards, which the programmer manipulates in their executable code to prove that the code correctly follows the protocol. Figure 6 shows one way to arrange an executable data structure to maintain the relationship between the concrete data and the corresponding ghost shards. The style is similar to that in IronSync.\n\nThe VerusSync approach lets Verus determine syntactically that the transition only affects two shards. This then allows the developer to perform the operation when they have ownership of those two shards without ownership of any of many other shards in system. Finally because VerusSync allows us to easily interpret this system as transition system we can use traditional state-machine techniques to prove global properties of ring buffer most notably that threads’ accesses to buffer entries are well-formed.",
    "page": 8,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "At the core of our NR case study (§4.2.2) is a ring buffer that tracks three pieces of state in shared memory:\n\n• a buffer for storing message entries,\n• a tail pointer where the next message goes, and\n• a per-thread head pointer, indicating where each thread should read the next message.\n\nThere is a complex, multi-step protocol for reading and processing messages from the queue. This protocol is implemented by a thread called the executor thread. As the queue operates, no one thread ever simultaneously owns all the pieces of state above, as they are accessed and updated concurrently. Even so, we maintain complex invariants, e.g., relating an executor thread’s internal state to its head pointers, or relating the head and tail pointers to non-empty buffer entries.\n\nWe model this protocol as a VerusSync protocol with fields representing the pieces of state, and we distribute the resulting shards across the threads. The ring buffer’s fields are shared with different strategies.\n\n• The tail field marks the next empty space. Its value is represented by a single shard that a thread must own to read or modify the field. The ghost shard is associated with a particular physical memory word accessed atomically, here via compare-and-swap.\n• The buffer_size field is constant: all threads agree on (“read”) its value at all times.\n• The local_versions field contains per-thread head-pointers into the queue. It is represented by a map where each entry is an owned shared, each associated with a different atomically-accessed memory word.\n• The executor field describes the intermediate state of each executor thread within its multi-step protocol.\n\nIn NR, an executor thread pops operations off the queue and processes them. The thread selects a range to read, reads each buffer entry in that range, and finally updates the atomic field corresponding to an entry of last_version to point to the end of this range. Figure 5 shows this final step of the protocol, as expressed in VerusSync. Verus then generates appropriate owned ghost shards, which the programmer manipulates in their executable code to prove that the code correctly follows the protocol. Figure 6 shows one way to arrange an executable data structure to maintain the relationship between the concrete data and the corresponding ghost shards. The style is similar to that in IronSync, which provides an in-depth example [29, §3.3.2].\n\nThe VerusSync approach lets Verus determine, syntactically, that the transition only affects two shards. This then allows the developer to perform the operation when they have ownership of those two shards without ownership of any of the many other shards in the system. Finally, because VerusSync allows us to easily interpret this system as a transition system, we can use traditional state-machine techniques to prove global properties of the ring buffer, most notably that the threads’ accesses to the buffer entries are well-formed.",
      "textWithCitationsRemoved": "At the core of our NR case study is a ring buffer that tracks three pieces of state in shared memory:\n\n• a buffer for storing message entries,\n• a tail pointer where the next message goes, and\n• a per-thread head pointer, indicating where each thread should read the next message.\n\nThere is a complex, multi-step protocol for reading and processing messages from the queue. This protocol is implemented by a thread called the executor thread. As the queue operates, no one thread ever simultaneously owns all the pieces of state above, as they are accessed and updated concurrently. Even so, we maintain complex invariants, e.g., relating an executor thread’s internal state to its head pointers, or relating the head and tail pointers to non-empty buffer entries.\n\nWe model this protocol as a VerusSync protocol with fields representing the pieces of state, and we distribute the resulting shards across the threads. The ring buffer’s fields are shared with different strategies.\n\n• The tail field marks the next empty space. Its value is represented by a single shard that a thread must own to read or modify the field. The ghost shard is associated with a particular physical memory word accessed atomically, here via compare-and-swap.\n• The buffer_size field is constant: all threads agree on (“read”) its value at all times.\n• The local_versions field contains per-thread head-pointers into the queue. It is represented by a map where each entry is an owned shared, each associated with a different atomically-accessed memory word.\n• The executor field describes the intermediate state of each executor thread within its multi-step protocol.\n\nIn NR, an executor thread pops operations off the queue and processes them. The thread selects a range to read, reads each buffer entry in that range, and finally updates the atomic field corresponding to an entry of last_version to point to the end of this range. Figure 5 shows this final step of the protocol, as expressed in VerusSync. Verus then generates appropriate owned ghost shards, which the programmer manipulates in their executable code to prove that the code correctly follows the protocol. Figure 6 shows one way to arrange an executable data structure to maintain the relationship between the concrete data and the corresponding ghost shards. The style is similar to that in IronSync.\n\nThe VerusSync approach lets Verus determine, syntactically, that the transition only affects two shards. This then allows the developer to perform the operation when they have ownership of those two shards without ownership of any of the many other shards in the system. Finally, because VerusSync allows us to easily interpret this system as a transition system, we can use traditional state-machine techniques to prove global properties of the ring buffer, most notably that the threads’ accesses to the buffer entries are well-formed."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "At the core of our NR case study is a ring buffer that tracks three pieces of state in shared memory:\n\n• a buffer for storing message entries,\n• a tail pointer where the next message goes, and\n• a per-thread head pointer, indicating where each thread should read the next message.\n\nThere is a complex, multi-step protocol for reading and processing messages from the queue. This protocol is implemented by a thread called the executor thread. As the queue operates, no one thread ever simultaneously owns all the pieces of state above, as they are accessed and updated concurrently. Even so, we maintain complex invariants, e.g., relating an executor thread’s internal state to its head pointers, or relating the head and tail pointers to non-empty buffer entries.\n\nWe model this protocol as a VerusSync protocol with fields representing the pieces of state, and we distribute the resulting shards across the threads. The ring buffer’s fields are shared with different strategies.\n\n• The tail field marks the next empty space. Its value is represented by a single shard that a thread must own to read or modify the field. The ghost shard is associated with a particular physical memory word accessed atomically, here via compare-and-swap.\n• The buffer_size field is constant: all threads agree on (“read”) its value at all times.\n• The local_versions field contains per-thread head-pointers into the queue. It is represented by a map where each entry is an owned shared, each associated with a different atomically-accessed memory word.\n• The executor field describes the intermediate state of each executor thread within its multi-step protocol.\n\nIn NR, an executor thread pops operations off the queue and processes them. The thread selects a range to read, reads each buffer entry in that range, and finally updates the atomic field corresponding to an entry of last_version to point to the end of this range. Figure 5 shows this final step of the protocol, as expressed in VerusSync. Verus then generates appropriate owned ghost shards, which the programmer manipulates in their executable code to prove that the code correctly follows the protocol. Figure 6 shows one way to arrange an executable data structure to maintain the relationship between the concrete data and the corresponding ghost shards. The style is similar to that in IronSync.\n\nThe VerusSync approach lets Verus determine, syntactically, that the transition only affects two shards. This then allows the developer to perform the operation when they have ownership of those two shards without ownership of any of the many other shards in the system. Finally, because VerusSync allows us to easily interpret this system as a transition system, we can use traditional state-machine techniques to prove global properties of the ring buffer, most notably that the threads’ accesses to the buffer entries are well-formed.",
      "wordedReplacement": "At the core of our NR case study is a ring buffer that tracks three pieces of state in shared memory:\n\n• a buffer for storing message entries,\n• a tail pointer where the next message goes, and\n• a per-thread head pointer, indicating where each thread should read the next message.\n\nThere is a complex, multi-step protocol for reading and processing messages from the queue. This protocol is implemented by a thread called the executor thread. As the queue operates, no one thread ever simultaneously owns all the pieces of state above, as they are accessed and updated concurrently. Even so, we maintain complex invariants, for example relating an executor thread’s internal state to its head pointers, or relating the head and tail pointers to non-empty buffer entries.\n\nWe model this protocol as a VerusSync protocol with fields representing the pieces of state, and we distribute the resulting shards across the threads. The ring buffer’s fields are shared with different strategies.\n\n• The tail field marks the next empty space. Its value is represented by a single shard that a thread must own to read or modify the field. The ghost shard is associated with a particular physical memory word accessed atomically, here via compare-and-swap.\n• The buffer size field is constant: all threads agree on \"read\" its value at all times.\n• The local versions field contains per-thread head-pointers into the queue. It is represented by a map where each entry is an owned shared, each associated with a different atomically-accessed memory word.\n• The executor field describes the intermediate state of each executor thread within its multi-step protocol.\n\nIn NR, an executor thread pops operations off the queue and processes them. The thread selects a range to read, reads each buffer entry in that range, and finally updates the atomic field corresponding to an entry of last version to point to the end of this range. Figure 5 shows this final step of the protocol, as expressed in VerusSync. Verus then generates appropriate owned ghost shards, which the programmer manipulates in their executable code to prove that the code correctly follows the protocol. Figure 6 shows one way to arrange an executable data structure to maintain the relationship between the concrete data and the corresponding ghost shards. The style is similar to that in IronSync.\n\nThe VerusSync approach lets Verus determine syntactically that the transition only affects two shards. This then allows the developer to perform the operation when they have ownership of those two shards without ownership of any of many other shards in system. Finally because VerusSync allows us to easily interpret this system as transition system we can use traditional state-machine techniques to prove global properties of ring buffer most notably that threads’ accesses to buffer entries are well-formed."
    },
    "optimizedMath": true
  },
  {
    "type": "code_or_algorithm",
    "content": "Figure 6  code explanation:\nThe code defines a structure called `NLog` in Rust. This structure manages an atomic type `AtomicU64`, which is part of Rust's standard library. The `NLog` structure uses a vector to hold instances of `AtomicU64`, with each instance corresponding to a replica. This setup allows for concurrent and safe manipulation of atomic memory cells, which is useful for maintaining consistency across multiple threads or replicas.",
    "page": 9,
    "label": {
      "labelType": "Figure",
      "labelNumber": "6",
      "panelNumber": "unlabeled"
    },
    "title": "NLog Structure for Atomic Management in Rust",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 5  summary:\nThis figure illustrates a more advanced example of the VerusSync protocol for managing a ring buffer in a multi-threaded environment. It includes code snippets that define states and transitions for managing shared memory components. The `ReaderState` and `ExecutorState` enums represent different operational states, such as Idle and Reading. The fields section outlines shared memory components like the tail pointer and executor states, each with specific sharding strategies. The `reader_finish` function transitions a node's state from Reading to Idle, ensuring the current position matches the end of the range before updating the executor and local versions maps. This transition is only possible if the thread owns two specific shards, allowing it to update the node_id version entry and transition the executor to Idle.",
    "page": 8,
    "label": {
      "labelType": "Figure",
      "labelNumber": "5",
      "panelNumber": "unlabeled"
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "code_or_algorithm",
    "content": "Figure 6  code explanation:\nThis code defines a proof function named `snbct_proof_mod_eq_zero` that uses integer ring reasoning to verify a mathematical property. The function takes three integer inputs: `a`, `b`, and `c`. It requires that `a` and `b` are not equal to `c` multiplied by some integer `m`. The function ensures that the product of `(a - b)` and `c` equals zero. This is achieved through custom proof automation, which is part of the Verus system's approach to handling nonlinear arithmetic reasoning efficiently.",
    "page": 6,
    "label": {
      "labelType": "Figure",
      "labelNumber": "6",
      "panelNumber": "unlabeled"
    },
    "title": "Proof Function for Modulo Equality",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 1
  },
  {
    "type": "code_or_algorithm",
    "content": "Figure 5  code explanation:\nThis code defines a protocol for managing the state of a ring buffer used in a multi-threaded environment. It uses enums to represent different states of a reader and executor. The `ReaderState` enum includes states for starting and processing a range of log indices. The `ExecutorState` enum includes states like Idle, Reading, and others related to advancing and appending operations. The fields section defines shared memory components such as the tail pointer, buffer size, local versions, and executor states, each with specific sharding strategies. The `reader_finish` function transitions a node's state from Reading to Idle, ensuring that the current position matches the end of the range before updating the executor and local versions maps.",
    "page": 8,
    "label": {
      "labelType": "Figure",
      "labelNumber": "5",
      "panelNumber": "unlabeled"
    },
    "title": "VerusSync Protocol for Ring Buffer Management",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "An executor thread completing an update takes this reader_finish transition, which is only possible if the thread owns two shards needed for power: one showing it either was owner on Reading a range that finishes at end, and another that proves it owns the right to mutate the node_id version entry. The transition replaces those shards (via add) with one that notes the executor is now Idle and another that stores end into the node_id version entry.",
    "page": 8,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4 Evaluation[break0.7]",
    "page": 8,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We evaluate Verus as a system verification language across two key dimensions. First, is its proof automation sufficiently powerful and fast for complex system verification? Second, is it expressive enough to specify important system properties and give developers the freedom to write high-performance code that satisfies them?\n\nAn ideal evaluation would build K large systems in N different frameworks; however, each such system might warrant an entire paper. Instead, we adopt a pragmatic, multi-scale evaluation strategy. First, we conduct “millibenchmarks” that compare Verus against many verification frameworks on small",
    "page": 8,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "code_or_algorithm",
    "content": "Code   code explanation:\nThe code defines an invariant for a collection called `local_versions`. It ensures that for each element in `local_versions`, the key of the `LocalVersionShard` matches its index, and the value is within a specified range. This invariant is used to maintain consistency in the data structure.",
    "page": 9,
    "label": {
      "labelType": "Code",
      "labelNumber": "unlabeled",
      "panelNumber": "unlabeled"
    },
    "title": "Invariant Definition for Local Versions",
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure   summary:\nThe image shows a graph with lines representing different verification frameworks: Versus, Creusot, Dafny, Low*, and Prusti. The graph likely compares performance metrics such as verification time or accuracy across these frameworks. Each line represents a framework's performance over a range of conditions or benchmarks. The context suggests that the graph is part of a study evaluating the efficiency and effectiveness of these frameworks in verifying complex system properties. The comparison aims to highlight the strengths and weaknesses of each framework in terms of speed and capability.",
    "page": 9,
    "label": {
      "labelType": "Figure",
      "labelNumber": "unlabeled",
      "panelNumber": "unlabeled"
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "table_rows",
    "content": "Table 7 Panel a summary:\nThe table compares verification times (in seconds) for different frameworks on singly and doubly linked list millibenchmarks. For singly linked lists, Versus is the fastest at 0.66 seconds, while Prusti is the slowest at 18.80 seconds. For doubly linked lists, Versus remains the fastest at 1.15 seconds, and Creusot is the slowest at 30.83 seconds. Prusti does not support doubly linked lists.",
    "page": 9,
    "label": {
      "labelType": "Table",
      "labelNumber": "7",
      "panelNumber": "a"
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Figure 6. Linking Executable Code to VerusSync Transitions.[break0.7]",
    "page": 9,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Through a combination of verified Verus primitives and verified utility code from Verus’s “standard library,” we can enable multiple, concurrently-running threads to manipulate the LocalVersionShard by associating it with an atomic memory cell that can be accessed in a safe, concurrent manner. To streamline this process, Verus provides the invariant on ... is ... syntax (shown here) to easily write a predicate that connects the ghost shard with the physical value of the atomic cell. When the code atomically updates the physical value, the code also invokes a Verus API to update the corresponding ghost shard (e.g., by invoking the reader_finish method), and maintain the invariant.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.1 Millibenchmark Evaluation[break0.7]",
    "page": 9,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We begin by designing a series of “millibenchmarks”, each large enough to capture an important system verification task, but small enough that we can implement them in multiple verification frameworks and analyze them in some detail. We measure the wall-clock time to verify each version. To reduce the risk that we use another verification framework naively, we draw our benchmarks from those provided by the frameworks themselves, so we presume they are reasonably optimized. Where we change examples or port new ones to existing frameworks, we have confirmed with the framework’s designers that our alterations are reasonably idiomatic.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.1.1 Frameworks[break0.7]",
    "page": 9,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We focus on comparison to verification frameworks that (a) have been used to verify complex properties of large-scale systems, and (b) offer a large degree of automation “out of the box”. This includes Dafny, which has verified cryptographic code, application stacks, distributed systems, storage systems, and production-scale multi-threaded systems; and F* (specifically the Low* subset), which has verified ~43K lines of C and assembly code in a cryptographic provider, the TLS 1.3 and QUIC record layers, and the Signal messaging protocol. We also include Ivy, which has verified distributed system protocols, as a representative of tools trading expressivity for proof automation.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We focus on comparison to verification frameworks that (a) have been used to verify complex properties of large-scale systems, and (b) offer a large degree of automation “out of the box”. This includes Dafny [34], which has verified cryptographic code [53, 59], application stacks [29], distributed systems [13], storage systems [16], and production-scale multi-threaded systems [29]; and F* [35] (specifically the Low* subset [60]), which has verified ~43K lines of C and assembly code in a cryptographic provider [14], the TLS 1.3 [61] and QUIC [62] record layers, and the Signal messaging protocol [63]. We also include Ivy [7, 8], which has verified distributed system protocols [9, 18–22], as a representative of tools trading expressivity for proof automation.",
      "textWithCitationsRemoved": "We focus on comparison to verification frameworks that (a) have been used to verify complex properties of large-scale systems, and (b) offer a large degree of automation “out of the box”. This includes Dafny, which has verified cryptographic code, application stacks, distributed systems, storage systems, and production-scale multi-threaded systems; and F* (specifically the Low* subset), which has verified ~43K lines of C and assembly code in a cryptographic provider, the TLS 1.3 and QUIC record layers, and the Signal messaging protocol. We also include Ivy, which has verified distributed system protocols, as a representative of tools trading expressivity for proof automation."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To confirm that Verus’s benefits arise from design decisions beyond simply building on Rust, we include two state-of-the-art automated Rust verification frameworks, Prusti and Creusot, even though they do not verify concurrent code and have not yet been applied to large-scale systems projects.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "To confirm that Verus’s benefits arise from design decisions beyond simply building on Rust, we include two state-of-the-art automated Rust verification frameworks, Prusti [64] and Creusot [65], even though they do not verify concurrent code and have not yet been applied to large-scale systems projects.",
      "textWithCitationsRemoved": "To confirm that Verus’s benefits arise from design decisions beyond simply building on Rust, we include two state-of-the-art automated Rust verification frameworks, Prusti and Creusot, even though they do not verify concurrent code and have not yet been applied to large-scale systems projects."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.1.2 Millibenchmarks[break0.7]",
    "page": 9,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We start by defining three general-purpose millibenchmarks on data structures: Linked lists, simple examples fall outside the restricted logics of Ivy or Verus, so we add a benchmark that fits in Ivy’s expressivity.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We start by defining three general-purpose millibenchmarks on data structures: Linked lists, simple examples fall outside the restricted logics of Ivy [8] or Verus [5], so we add a benchmark that fits in Ivy’s expressivity.",
      "textWithCitationsRemoved": "We start by defining three general-purpose millibenchmarks on data structures: Linked lists, simple examples fall outside the restricted logics of Ivy or Verus, so we add a benchmark that fits in Ivy’s expressivity."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Singly linked list. To evaluate how verification performance scales with complexity, we implement a singly linked list on a small task, we verify that a singly linked list implements an abstract sequence. The verified API is consistent across the verification tools. The list supports pushing at the head, popping at the tail, indexing, and iteration.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Doubly linked list. To evaluate how verification performance scales with complexity, we implement a doubly linked list and prove it implements an abstract sequence, which requires unsafe Rust because of its cyclic pointers. This list supports pushing and popping at both ends and iteration.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Memory reasoning. Reasoning about memory updates at scale is a perennial challenge for system verification. Hence, using the verified lists, we evaluate the cost of memory reasoning by repeatedly updating four instances of the list within the same function and then asserting basic facts about other elements of the lists. This requires the verifiers to determine whether an update to one list might affect another.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Distributed lock. To evaluate distributed protocols, we port a distributed lock to Verus and prove mutual exclusion in two ways: in default-mode following the Dafny proof, and using Verus’s EPR mode, similar to the Ivy proof.",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Distributed lock. To evaluate distributed protocols, we port a distributed lock to Verus and prove mutual exclusion in two ways: in default-mode following the Dafny proof [71], and using Verus’s EPR mode, similar to the Ivy proof [7].",
      "textWithCitationsRemoved": "Distributed lock. To evaluate distributed protocols, we port a distributed lock to Verus and prove mutual exclusion in two ways: in default-mode following the Dafny proof, and using Verus’s EPR mode, similar to the Ivy proof."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.1.3 Millibenchmark Results Linked lists.[break0.7]",
    "page": 9,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Figure 7a shows the verification time for our two linked list examples. For the singly linked list, we see that the other frameworks take 3–28× longer than Verus, while for the more complex",
    "page": 9,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "doubly linked list, they take 24 to 61 times longer. A major cause is Verus’s emphasis on concise SMT queries (Figure 9).",
    "page": 10,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "doubly linked list, they take 24–61× longer. A major cause is Verus’s emphasis on concise SMT queries (§3.1, Figure 9).",
      "textWithCitationsRemoved": "doubly linked list, they take 24–61× longer. A major cause is Verus’s emphasis on concise SMT queries (Figure 9)."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "doubly linked list, they take 24–61× longer. A major cause is Verus’s emphasis on concise SMT queries (Figure 9).",
      "wordedReplacement": "doubly linked list, they take 24 to 61 times longer. A major cause is Verus’s emphasis on concise SMT queries (Figure 9)."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "Successful verification times are the easiest apples-to-apples comparison, but in reality, developers most often wait on tools for failure feedback. To capture this, we “break” each singly-linked-list proof twice, once by removing a precondition in pop and once in index, and measure the time for the tool to report an error. Figure 8 shows that Verus, Dafny, and Prusti pinpoint failures as quickly as they report success. Low* degenerates from one second to four. Creusot’s approach degenerates from one second to twenty.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 8  summary:\nThis figure presents error results for various verification tools, showing the median of 20 runs using 8 threads. The graph compares the time taken for successful verification and error detection across different tools. The tools include Verus, Dafny, Prusti, Low*, and Creusot. The results indicate that Verus, Dafny, and Prusti are efficient in pinpointing failures as quickly as they report successes. However, Low* and Creusot show a significant increase in time when errors occur, with Creusot's approach degenerating from one second to twenty seconds. This highlights the efficiency of Verus, Dafny, and Prusti in handling verification tasks compared to Low* and Creusot.",
    "page": 10,
    "label": {
      "labelType": "Figure",
      "labelNumber": "8",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 8  summary:\nThis figure presents error results for various verification tools, showing the median of 20 runs using 8 threads. The graph compares the time taken for successful verification and error detection across different tools, including Verus, Dafny, Prusti, Low*, and Creusot. Verus, Dafny, and Prusti are efficient in pinpointing failures as quickly as they report successes. However, Low* and Creusot show a significant increase in time when errors occur, with Creusot's approach degenerating from one second to twenty seconds. This highlights the efficiency of Verus, Dafny, and Prusti in handling verification tasks compared to Low* and Creusot.",
    "page": 10,
    "label": {
      "labelType": "Figure",
      "labelNumber": "8",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Memory reasoning. Figure seven b shows how the verification frameworks handle increasing numbers of memory modifications to four singly linked lists. Dafny and Low star must perform complex aliasing reasoning, and hence Dafny’s verification time grows dramatically as memory modifications increase. Low star struggles even more, taking over ten seconds after just one push. Prior Rust-based tools perform better, but they still grow super-linearly, whereas Verus remains linear with a slope of approximately one point six milliseconds per push across the entire benchmark. The results for doubly linked lists are similar, with Verus remaining linear with a slope of approximately one point eight milliseconds per push.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "Memory reasoning. Figure 7b shows how the verification frameworks handle increasing numbers of memory modifications to four singly linked lists. Dafny and Low* must perform complex aliasing reasoning, and hence Dafny’s verification time grows dramatically as memory modifications increase. Low* struggles even more, taking over ten seconds after just one push. Prior Rust-based tools perform better, but they still grow super-linearly,3 whereas Verus remains linear (with a slope of ~1.6ms/push) across the entire benchmark. The results for doubly linked lists are similar, with Verus remaining linear with a slope of ~1.8ms/push.",
      "wordedReplacement": "Memory reasoning. Figure seven b shows how the verification frameworks handle increasing numbers of memory modifications to four singly linked lists. Dafny and Low star must perform complex aliasing reasoning, and hence Dafny’s verification time grows dramatically as memory modifications increase. Low star struggles even more, taking over ten seconds after just one push. Prior Rust-based tools perform better, but they still grow super-linearly, whereas Verus remains linear with a slope of approximately one point six milliseconds per push across the entire benchmark. The results for doubly linked lists are similar, with Verus remaining linear with a slope of approximately one point eight milliseconds per push."
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "Distributed lock. The safety proof uses an inductive invariant maintained across protocol steps. The default-mode proof of inductiveness is around ~25 lines. When abstracted into EPR, the proof is automatic, but creating and using the abstraction required ~100 lines of (straightforward) boilerplate. While this example demonstrates that Verus’s EPR mode applies to protocols as well as data structures, the excessive boilerplate suggests that (a) EPR benefits complex examples, like the Delegation Map in §3.2, more than simple ones, and (b) Verus needs to automate the boilerplate.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2 Macrobenchmarks[break0.7]",
    "page": 10,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To show that the benefits of Verus identified by the millibenchmarks translate into benefits at scale, we assembled a suite of macrobenchmarks. First, to compare with other frameworks at scale, we port two large verified systems to Verus and compare each to its original.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "To show that the benefits of Verus identified by the millibenchmarks translate into benefits at scale, we assembled a suite of macrobenchmarks. First, to compare with other frameworks at scale, we port two large verified systems to Verus (§4.2.1, §4.2.2) and compare each to its original.",
      "textWithCitationsRemoved": "To show that the benefits of Verus identified by the millibenchmarks translate into benefits at scale, we assembled a suite of macrobenchmarks. First, to compare with other frameworks at scale, we port two large verified systems to Verus and compare each to its original."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Second, since developers rarely start from completed code and proofs, we examine the tool’s behavior in its primary mode, when verification fails. To explore fresh development,",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "we report on the experience of writing and verifying three additional systems from scratch in Verus.",
    "page": 10,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "we report on the experience of writing and verifying three additional systems from scratch in Verus (§4.2.3–§4.2.5).",
      "textWithCitationsRemoved": "we report on the experience of writing and verifying three additional systems from scratch in Verus."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "table_rows",
    "content": "Table 9  summary:\nThe table compares verification performance across different systems and verifiers. IronKV verified with Verus shows a proof-to-code ratio of 2.9 and takes 41 seconds to prove, while Dafny has a higher ratio of 4.2 and takes significantly longer at 445 seconds. NR with Verus has a ratio of 7.1 and takes 17 seconds, whereas L.Dafny has a ratio of 10.7 and takes 1089 seconds. The page table has the highest proof-to-code ratio of 13.3, taking 63 seconds to prove. Mimalloc has a ratio of 4.3, with a proving time of 262 seconds. P_log shows a ratio of 3.9, with a proving time of 12 seconds. Overall, Verus totals a proof-to-code ratio of 5.1.",
    "page": 10,
    "label": {
      "labelType": "Table",
      "labelNumber": "9",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 1
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2.1 Porting IronKV from IronFleet [13] IronFleet [13], originally developed in Dafny, allows developers to prove that a distributed system’s implementation meets its specification.[break0.7]",
    "page": 10,
    "hasCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "This requires proofs about both the implementation that runs on each host, and the protocol those hosts use to achieve the system’s high-level properties.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Verification Target.[break0.7]",
    "page": 10,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We port the host implementation of IronFleet’s IronKV, which dynamically shards a key-value store across a set of nodes.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We skip the protocol level, since Dafny and Verus share similar mathematical modeling tools and are likely to admit very similar proofs.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We translate the protocol-level host description to Verus as the spec implementation the host in Rust, and prove it matches this spec.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Porting Experience.[break0.7]",
    "page": 10,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To support comparisons, our port preserves IronKV’s algorithmic decisions, but, where highlighted below, our design exploits Verus-enabled improvements.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Basic Improvements[break0.7]",
    "page": 10,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We encountered multiple places where IronFleet split a simple task across many functions, presumably to keep verification times manageable.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "For example, IronFleet’s MaybeAc kPacketImpl accepts a message and looks up its sequence number in a tombstone table to decide whether to ack it.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In IronFleet, this simple task is split into three functions across 37 lines.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Our port inlined those three functions into a single 30-line Verus function that verifies faster than any of the three original Dafny functions.",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In another place, the IronFleet code dealt with the painfulness of reasoning about fine-grained mutation by replacing an entire data structure with a modified version,",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": ", leading to an inefficient (and confusing) code.",
    "page": 10,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The Verus port simply uses an &mut reference,",
    "page": 10,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": ", which expresses the original intent directly and avoids a performance penalty.",
    "page": 10,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Parsing and Marshalling[break0.7]",
    "page": 11,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In IronFleet’s IronKV there is a generic marshalling library for basic types: arrays, tuples, tagged unions, 64-bit integers, and byte-arrays. The developers mapped Dafny datatypes to and from these basic types, manually constructing tedious boilerplate code and proofs.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We instead wrote our own marshalling library that eliminates this tedium via user-defined macros and provides a more ergonomic interface using traits. Our Marshallable trait, provides a consistent interface, improving on the original which relies on naming convention. Primitives and repetition implement this trait with hand-written proofs. Arbitrary structs and enums use macros that automatically drive implementation and proofs, eliminating the repetitive manual process from IronFleet.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We instead wrote our own marshalling library that eliminates this tedium via user-defined macros (§3.3) and provides a more ergonomic interface using traits. Our Marshallable trait (including a marshaller, parser, and relevant lemmas), provides a consistent interface, improving on the original which relies on naming convention. Primitives (like u64) and repetition (Vec<T>) implement this trait with hand-written proofs. Arbitrary structs and enums use macros that automatically drive implementation and proofs, eliminating the repetitive manual process from IronFleet.",
      "textWithCitationsRemoved": "We instead wrote our own marshalling library that eliminates this tedium via user-defined macros and provides a more ergonomic interface using traits. Our Marshallable trait, provides a consistent interface, improving on the original which relies on naming convention. Primitives and repetition implement this trait with hand-written proofs. Arbitrary structs and enums use macros that automatically drive implementation and proofs, eliminating the repetitive manual process from IronFleet."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "EPR Delegation Map Proof Using Verus’s EPR mode dramatically simplified the proof of this data structure (§3.2).",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Evaluation. Figure 9 shows that the Verus port saves both code and proof, improving the proof-to-code ratio. The trusted column is noisy because of how we reinterpreted the original protocol layer as our spec. The authors that completed this port reported crisp interactivity, supported by the 95% smaller query sizes and 10× faster verification.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To confirm the fidelity of our port, we benchmark both systems with the harness from IronFleet’s repository. The experiment is run on Windows 11 Enterprise on a 2.4GHz Intel Core i9-10885H CPU &core laptop with 64GiB of RAM. We launch three server processes on separate ports, then launch the client workload generator with 10 threads and 10,000 keys for 30 seconds. We vary the workload (Get vs. Set) and the payload size (currently limited to 512 bytes by the IronFleet repository). Since our port is fairly faithful, we anticipated similar performance, which Figure 10 confirms.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "To confirm the fidelity of our port, we benchmark both systems with the harness from IronFleet’s repository [66]. The experiment is run on Windows 11 Enterprise on a 2.4GHz Intel Core i9-10885H CPU &core laptop with 64GiB of RAM. We launch three server processes on separate ports, then launch the client workload generator with 10 threads and 10,000 keys for 30 seconds. We vary the workload (Get vs. Set) and the payload size (currently limited to 512 bytes by the IronFleet repository). Since our port is fairly faithful, we anticipated similar performance, which Figure 10 confirms.",
      "textWithCitationsRemoved": "To confirm the fidelity of our port, we benchmark both systems with the harness from IronFleet’s repository. The experiment is run on Windows 11 Enterprise on a 2.4GHz Intel Core i9-10885H CPU &core laptop with 64GiB of RAM. We launch three server processes on separate ports, then launch the client workload generator with 10 threads and 10,000 keys for 30 seconds. We vary the workload (Get vs. Set) and the payload size (currently limited to 512 bytes by the IronFleet repository). Since our port is fairly faithful, we anticipated similar performance, which Figure 10 confirms."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 10  summary:\nThis bar chart compares the throughput of IronFleet and Verus at different payload sizes, measured in kilobytes per second (kops/s). The x-axis represents different payload sizes ranging from 128 bytes to 512 bytes, and the y-axis represents throughput. Each bar shows the mean throughput over 100 trials, with error bars indicating 95% confidence intervals. The chart demonstrates that Verus performs comparably to the original IronFleet across all payload sizes tested, confirming the fidelity of the Verus port in maintaining performance.",
    "page": 11,
    "label": {
      "labelType": "Figure",
      "labelNumber": "10",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Summary. Our success porting the IronKV test demonstrates that Verus at least subsumes the functionality of Dafny employed by IronFleet, and that it is largely compatible with that approach to system verification. It improves by moving heap reasoning into ownership reasoning, which eases performant implementation of mutable data structures and, by optimizing solver performance, enables coalescing tasks into more reasonably-sized functions. Rust’s macro system and Verus’s EPR support significantly reduce developer tedium.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2.2 Porting NR from IronSync [29][break0.7]",
    "page": 11,
    "hasCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The IronSync framework enables verifying the correctness of complex shared-memory programs that employ application-specific synchronization primitives to achieve high performance. It is built on Linear Dafny, a variant of Dafny extended with simple Rust-inspired ownership types.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "The IronSync framework [29] enables verifying the correctness of complex shared-memory programs that employ application-specific synchronization primitives to achieve high performance. It is built on Linear Dafny [67], a variant of Dafny extended with simple Rust-inspired ownership types.",
      "textWithCitationsRemoved": "The IronSync framework enables verifying the correctness of complex shared-memory programs that employ application-specific synchronization primitives to achieve high performance. It is built on Linear Dafny, a variant of Dafny extended with simple Rust-inspired ownership types."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Verification Target. We ported the IronSync implementation of the Node Replication (NR) concurrency library. NR converts a sequential data structure into a high-performance, concurrent version via replication and flat combining. We prove the same result as IronSync, namely that the concurrent system meets the sequential function spec linearlizably.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Verification Target. We ported the IronSync implementation of the Node Replication (NR) concurrency library [68]. NR converts a sequential data structure into a high-performance, concurrent version via replication and flat combining. We prove the same result as IronSync, namely that the concurrent system meets the sequential function spec linearlizably.",
      "textWithCitationsRemoved": "Verification Target. We ported the IronSync implementation of the Node Replication (NR) concurrency library. NR converts a sequential data structure into a high-performance, concurrent version via replication and flat combining. We prove the same result as IronSync, namely that the concurrent system meets the sequential function spec linearlizably."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Porting Experience. Our Verus-NR implementation is more faithful to the original NR than IronSync-NR in three ways. First, both NR and Verus-NR are written in Rust; IronSync-NR was a port to Dafny. Second, Verus-NR exposes a trait-based interface similar to NR’s in order to support generic data structures, whereas IronSync does not support traits. Finally, Verus-NR avoids runtime-defined contexts and dynamic thread registration, whereas IronSync-NR fixes the thread and replica counts statically.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Furthermore, proofs related to concurrency are substantially simplified in Verus-NR due to the use of VerusSync rather than IronSync’s monoid formalism. VerusSync allows cleaner, application-level reasoning, and this simplification is reflected in our reduction in proof code.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Furthermore, proofs related to concurrency are substantially simplified in Verus-NR due to the use of VerusSync (§3.4) rather than IronSync’s monoid formalism. VerusSync allows cleaner, application-level reasoning, and this simplification is reflected in our reduction in proof code.",
      "textWithCitationsRemoved": "Furthermore, proofs related to concurrency are substantially simplified in Verus-NR due to the use of VerusSync rather than IronSync’s monoid formalism. VerusSync allows cleaner, application-level reasoning, and this simplification is reflected in our reduction in proof code."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Evaluation. Figure 9 shows that Verus-NR requires far fewer lines of proof. This is mostly due to the use of VerusSync. Verus also improves the verification time by two orders of magnitude. Such speed creates a qualitative advantage: Where we might verify one function at a time with a slower tool, we iterated while verifying the entire project, which provides an early warning when a change to a function contract breaks a proof elsewhere.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We compare Verus-NR’s performance with unverified NR and with IronSync-NR using the benchmark from IronSync’s artifact. We run this benchmark on a four-socket Intel Xeon Platinum 8260 with 24 cores and hyper-threading enabled. The benchmark initializes NR with four replicas wrapping an x86-page-table data structure. We increase thread count, filling up NUMA cores before utilizing hyperthreads, and measure the throughput at write ratios of 0%, 10%, and 100%. Figure 11 shows that Verus-NR’s performance matches the unverified, highly optimized original implementation.",
    "page": 11,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We compare Verus-NR’s performance with unverified NR and with IronSync-NR using the benchmark from IronSync’s artifact [69]. We run this benchmark on a four-socket Intel Xeon Platinum 8260 with 24 cores and hyper-threading enabled. The benchmark initializes NR with four replicas wrapping an x86-page-table data structure. We increase thread count, filling up NUMA cores before utilizing hyperthreads, and measure the throughput at write ratios of 0%, 10%, and 100%. Figure 11 shows that Verus-NR’s performance matches the unverified, highly optimized original implementation.",
      "textWithCitationsRemoved": "We compare Verus-NR’s performance with unverified NR and with IronSync-NR using the benchmark from IronSync’s artifact. We run this benchmark on a four-socket Intel Xeon Platinum 8260 with 24 cores and hyper-threading enabled. The benchmark initializes NR with four replicas wrapping an x86-page-table data structure. We increase thread count, filling up NUMA cores before utilizing hyperthreads, and measure the throughput at write ratios of 0%, 10%, and 100%. Figure 11 shows that Verus-NR’s performance matches the unverified, highly optimized original implementation."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 11  summary:\nThis figure presents a line graph comparing the performance of NR, IronSync-NR, and Verus-NR at different write ratios (0%, 10%, and 100%). The x-axis represents the number of threads, while the y-axis shows throughput. Each line represents one of the three systems. The graph demonstrates that Verus-NR matches the performance of IronSync-NR and the unverified original NR across all write ratios, indicating that Verus-NR maintains high performance while simplifying the proof process.",
    "page": 11,
    "label": {
      "labelType": "Figure",
      "labelNumber": "11",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "abstract_content",
    "content": "Porting NR shows that Verus can verify state-of-the-art concurrent data structures optimized via application-specific synchronization primitives. It does so faster, more intuitively, and with less developer tedium than existing state-of-the-art concurrent verifiers.",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2.3 New Verified System: An OS Page Table[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To evaluate Verus when developing a new verified system, we implement a verified page-table data structure for x86-64.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Verification Target.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The map and unmap operations of a page table entail traversing and modifying a tree data structure whose nodes pack flags and addresses into 64-bit machine words. Verifying it requires specifying and reasoning about ISA-level software and hardware components.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Correctness is specified from the perspective of a user-space process in a single-processor system: reads return the most recently written value; map and unmap operations expand and restrict the virtual memory domain. The implementation employs a (trusted) hardware spec that defines how the MMU interprets page table memory to translate virtual addresses to physical.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Development Experience.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We highlight how two aspects of how Verus enables necessary low-level reasoning: bit-level manipulation of 64-bit words and specifying how the implementation may interact with page-table memory.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Page-table entries are bit-packed sixty-four-bit words. To reason about correctness, they rely heavily on custom automation for bit-vector, nonlinear, and proof-by-computation reasoning, which we invoke, see twenty-nine, and eleven times, respectively. They enable us to automatically discharge conditions like:",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Page-table entries are bit-packed 64-bit words. To reason about correctness, they rely heavily on custom automation for bit-vector, nonlinear, and proof-by-computation reasoning (§3.3), which we invoke, see 29, and 11 times, respectively. They enable us to automatically discharge conditions like:",
      "textWithCitationsRemoved": "Page-table entries are bit-packed 64-bit words. To reason about correctness, they rely heavily on custom automation for bit-vector, nonlinear, and proof-by-computation reasoning, which we invoke, see 29, and 11 times, respectively. They enable us to automatically discharge conditions like:"
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 1,
    "mathReplacement": {
      "originalText": "Page-table entries are bit-packed 64-bit words. To reason about correctness, they rely heavily on custom automation for bit-vector, nonlinear, and proof-by-computation reasoning, which we invoke, see 29, and 11 times, respectively. They enable us to automatically discharge conditions like:",
      "wordedReplacement": "Page-table entries are bit-packed sixty-four-bit words. To reason about correctness, they rely heavily on custom automation for bit-vector, nonlinear, and proof-by-computation reasoning, which we invoke, see twenty-nine, and eleven times, respectively. They enable us to automatically discharge conditions like:"
    },
    "optimizedMath": true
  },
  {
    "type": "math",
    "content": "For all i, u sixty-four, i, u sixty-four: (x is less than thirteen and (mask one of thirteen u sixty-four and twenty-nine u sixty-four is equal to zero) implies ((a of i bitst of i:) divided by mask one of thirteen u sixty-four and twenty-nine u sixty-four is equal to zero)",
    "mathSymbolFrequency": 5,
    "page": 12,
    "hasCitations": false,
    "mathReplacement": {
      "originalText": "\\forall i,u64,i,u64 : (x < 13 && (mask1(13u64,29u64) == 0) ==> ((a[i] bitst(i):) \\ mask1(13u64,29u64) == 0)",
      "wordedReplacement": "For all i, u sixty-four, i, u sixty-four: (x is less than thirteen and (mask one of thirteen u sixty-four and twenty-nine u sixty-four is equal to zero) implies ((a of i bitst of i:) divided by mask one of thirteen u sixty-four and twenty-nine u sixty-four is equal to zero)"
    },
    "optimizedMath": true
  },
  {
    "type": "text",
    "content": "which on other frameworks would have incurred tedious manual proof.",
    "page": 12,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "which on other frameworks [34, 35] would have incurred tedious manual proof [14, 54].",
      "textWithCitationsRemoved": "which on other frameworks would have incurred tedious manual proof."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The trusted spec of the MMU describes how it translates memory accesses based on the values of page table entries. This interpretation is only meaningful with respect to the physical values in the memory storing the page table. The trusted spec provides a struct that encapsulates ownership (and allocation) of the page-table memory: ownership prevents other writes to the entries, the encapsulation tracks the values of the entries as ghost state, and the MMU contract can thereby make promises about its translation. Ownership facilitates soundly specifying this hardware behavior.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Evaluation.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "As shown in Figure 9, our page table consists of 400 lines of executable code, which required 5329 lines of proof, resulting in a relatively high 13.3:1 proof-to-code ratio. This may be a result of this being our first large-scale development in Verus; more experience may suggest different abstractions for some proofs. A page table is also a complex OS component, so a high ratio may be inevitable. When it comes to verifying a complex OS, independent work uses Verus to verify a full microkernel; the authors report a 7.5:1 proof-to-code ratio.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "As shown in Figure 9, our page table consists of 400 lines of executable code, which required 5329 lines of proof, resulting in a relatively high 13.3:1 proof-to-code ratio. This may be a result of this being our first large-scale development in Verus; more experience may suggest different abstractions for some proofs. A page table is also a complex OS component, so a high ratio may be inevitable. When it comes to verifying a complex OS, independent work uses Verus to verify a full microkernel [26]; the authors report a 7.5:1 proof-to-code ratio.",
      "textWithCitationsRemoved": "As shown in Figure 9, our page table consists of 400 lines of executable code, which required 5329 lines of proof, resulting in a relatively high 13.3:1 proof-to-code ratio. This may be a result of this being our first large-scale development in Verus; more experience may suggest different abstractions for some proofs. A page table is also a complex OS component, so a high ratio may be inevitable. When it comes to verifying a complex OS, independent work uses Verus to verify a full microkernel; the authors report a 7.5:1 proof-to-code ratio."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "We compare our implementation against a recent unverified page table implementation in a single-threaded setting, reporting mean latency over 100M map and unmap operations on 4K frames. Figure 12 shows our implementation matches the reference for mapping frames, but our unmap is much slower. This discrepancy is because we reclaim emptied page directories, which we confirm by benchmarking an modification of our page table with reclamation disabled in the figure. Larger OS-level benchmarks show negligible differences, even with the cost of our unmap.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "We compare our implementation against a recent unverified page table implementation [68] in a single-threaded setting, reporting mean latency over 100M map and unmap operations on 4K frames. Figure 12 shows our implementation matches the reference for mapping frames, but our unmap is much slower. This discrepancy is because we reclaim emptied page directories, which we confirm by benchmarking an (unverified) modification of our page table with reclamation disabled (Unmap(Verif.*) in the figure). Larger OS-level benchmarks show negligible differences, even with the cost of our unmap.",
      "textWithCitationsRemoved": "We compare our implementation against a recent unverified page table implementation in a single-threaded setting, reporting mean latency over 100M map and unmap operations on 4K frames. Figure 12 shows our implementation matches the reference for mapping frames, but our unmap is much slower. This discrepancy is because we reclaim emptied page directories, which we confirm by benchmarking an modification of our page table with reclamation disabled in the figure. Larger OS-level benchmarks show negligible differences, even with the cost of our unmap."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 12  summary:\nThis figure presents a bar chart comparing the run-time performance of different page table operations. The operations include Map Base, Map Verif, Unmap Base, and Unmap Verif. The x-axis represents time in milliseconds, ranging from 0 to 320, while the y-axis lists the operations. The chart shows that the Map Base and Map Verif operations have similar performance, with Map Verif slightly slower. However, Unmap Verif is significantly slower than Unmap Base, indicating a performance discrepancy in unmap operations due to reclamation processes. This suggests that while the verified implementation matches the reference for mapping, it is less efficient in unmapping.",
    "page": 12,
    "label": {
      "labelType": "Figure",
      "labelNumber": "12",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "abstract_content",
    "content": "This system demonstrates Verus’s ability to specify both OS and hardware interfaces and reason about a complex low-level implementation concerning the two.",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2.4 New Verified System: Memory Allocator[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Verification Target.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Our work is based on mimalloc, which provides state-of-the-art performance. Since mimalloc is written in C, our Verus version translates C into Rust idioms, but preserves the overall data structures and algorithms. We prove our implementation functionally correct, meaning that every allocation returns non-aliased memory.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Our work is based on mimalloc [70], which provides state-of-the-art performance. Since mimalloc is written in C, our Verus version translates C into Rust idioms, but preserves the overall data structures and algorithms. We prove our implementation functionally correct, meaning that every allocation returns non-aliased memory.",
      "textWithCitationsRemoved": "Our work is based on mimalloc, which provides state-of-the-art performance. Since mimalloc is written in C, our Verus version translates C into Rust idioms, but preserves the overall data structures and algorithms. We prove our implementation functionally correct, meaning that every allocation returns non-aliased memory."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Development Experience.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Any memory allocator system faces two significant challenges:",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Address space management.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The overall objective of a memory allocator is to bridge the gap between an OS memory API that supports coarse-grained, page-aligned allocations (e.g., the mmap syscall on Linux) and an allocator API supporting arbitrary-sized allocations (free and malloc). This requires careful accounting of the address space.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]Cross-thread deallocations.[break0.7]",
    "page": 12,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "A client may free memory on a different thread from which it was originally allocated. Mimalloc’s design handles this by depositing cross-thread deallocations into an atomic free list, a lock-free linked list accessed via atomic compare-and-swap.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To do the same, we utilize Verus’s ability to associate ghost state with atomic locations. Specifically, we deposit ghost memory permissions from cross-thread deallocations into the atomic variable holding the linked list’s head pointer.",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "To do the same, we utilize Verus’s ability to associate ghost state with atomic locations (§3.4). Specifically, we deposit ghost memory permissions from cross-thread deallocations into the atomic variable holding the linked list’s head pointer.",
      "textWithCitationsRemoved": "To do the same, we utilize Verus’s ability to associate ghost state with atomic locations. Specifically, we deposit ghost memory permissions from cross-thread deallocations into the atomic variable holding the linked list’s head pointer."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Both address space management and cross-thread deallocations are challenging due to the complexity of memory",
    "page": 12,
    "isStartCutOff": false,
    "isEndCutOff": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "ownership across threads. This complex ownership structure is implicit in the original C codebase; porting to verified Rust requires us to make the ownership structure explicit. With ghost types, this is possible (and necessary) to a degree even beyond what could be done in unverified, unsafe Rust.\n\nEvaluation. We have implemented a subset of the features and optimizations supported by mimalloc’s design. For comparison’s sake, Verus-mimalloc has about 3.1K lines of executable code, while the original is about 10K lines of code. Our allocator supports use as a drop-in replacement for several root allocators, aligned allocations, or allocations greater than 128KiB. It can complete 8 out of 19 benchmarks from mimalloc’s benchmark suite, though it does not yet reach performance parity. We focused our initial development on aspects highlighted in the mimalloc report, particularly those affecting concurrency, so we believe Verus-mimalloc is prepared to support the missing features and optimizations in the future.\n\nFigure 9 shows a favorable proof-to-code ratio of 4:3. Furthermore, the allocator’s user-facing specification is very succinct: between initialize, malloc, and free, it is only 37 lines. The allocator relies on OS interfaces (mmap and thread utilities) with 245 lines of trusted spec, bringing the total to 282. Our allocator also relies heavily on Verus’s bit-vector, nonlinear, and proof-by-computation automation, which we invoke 78, 71, and 187 times, respectively.\n\nSummary. Totaling over 17.2K lines (code and proof), Verus-mimalloc is the largest of our macrobenchmarks and the largest Verus project we know of. Even so, Verus verifies the entire project in just over a minute.",
    "page": 13,
    "isStartCutOff": true,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "ownership across threads. This complex ownership structure is implicit in the original C codebase; porting to verified Rust requires us to make the ownership structure explicit. With ghost types, this is possible (and necessary) to a degree even beyond what could be done in unverified, unsafe Rust.\n\nEvaluation. We have implemented a subset of the features and optimizations supported by mimalloc’s design. For comparison’s sake, Verus-mimalloc has about 3.1K lines of executable code, while the original is about 10K lines of code. Our allocator supports use as a drop-in replacement for several root allocators, aligned allocations, or allocations greater than 128KiB. It can complete 8 out of 19 benchmarks from mimalloc’s benchmark suite [71], though it does not yet reach performance parity [Figure 13]. We focused our initial development on aspects highlighted in the mimalloc report [70], particularly those affecting concurrency, so we believe Verus-mimalloc is prepared to support the missing features and optimizations in the future.\n\nFigure 9 shows a favorable proof-to-code ratio of 4:3. Furthermore, the allocator’s user-facing specification is very succinct: between initialize, malloc, and free, it is only 37 lines. The allocator relies on OS interfaces (mmap and thread utilities) with 245 lines of trusted spec, bringing the total to 282. Our allocator also relies heavily on Verus’s bit-vector, nonlinear, and proof-by-computation automation (§3.3), which we invoke 78, 71, and 187 times, respectively.\n\nSummary. Totaling over 17.2K lines (code and proof), Verus-mimalloc is the largest of our macrobenchmarks and the largest Verus project we know of. Even so, Verus verifies the entire project in just over a minute.",
      "textWithCitationsRemoved": "ownership across threads. This complex ownership structure is implicit in the original C codebase; porting to verified Rust requires us to make the ownership structure explicit. With ghost types, this is possible (and necessary) to a degree even beyond what could be done in unverified, unsafe Rust.\n\nEvaluation. We have implemented a subset of the features and optimizations supported by mimalloc’s design. For comparison’s sake, Verus-mimalloc has about 3.1K lines of executable code, while the original is about 10K lines of code. Our allocator supports use as a drop-in replacement for several root allocators, aligned allocations, or allocations greater than 128KiB. It can complete 8 out of 19 benchmarks from mimalloc’s benchmark suite, though it does not yet reach performance parity. We focused our initial development on aspects highlighted in the mimalloc report, particularly those affecting concurrency, so we believe Verus-mimalloc is prepared to support the missing features and optimizations in the future.\n\nFigure 9 shows a favorable proof-to-code ratio of 4:3. Furthermore, the allocator’s user-facing specification is very succinct: between initialize, malloc, and free, it is only 37 lines. The allocator relies on OS interfaces (mmap and thread utilities) with 245 lines of trusted spec, bringing the total to 282. Our allocator also relies heavily on Verus’s bit-vector, nonlinear, and proof-by-computation automation, which we invoke 78, 71, and 187 times, respectively.\n\nSummary. Totaling over 17.2K lines (code and proof), Verus-mimalloc is the largest of our macrobenchmarks and the largest Verus project we know of. Even so, Verus verifies the entire project in just over a minute."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "table_rows",
    "content": "Table 13  summary:\nThe table compares the performance of mimalloc and Verus-mimalloc across various benchmarks. Verus-mimalloc generally shows slower performance than mimalloc. For example, in the cfrac benchmark, Verus-mimalloc takes 9.7 seconds compared to mimalloc's 4.6 seconds. Similarly, in the larsonN-sized benchmark, Verus-mimalloc takes 12.0 seconds versus mimalloc's 4.1 seconds. However, for cache-scratch1 and cache-scratchN, both allocators perform equally. Overall, Verus-mimalloc does not yet reach performance parity with mimalloc.",
    "page": 13,
    "label": {
      "labelType": "Table",
      "labelNumber": "13",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]4.2.5 New Verified System: Persistent Log[break0.7]",
    "page": 13,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "To evaluate Verus’s utility for verifying production code, we developed a persistent circular log for byte-addressable storage devices.\n\nVerification Target. The log offers asynchronous append and synchronous advance_head operations to its storage system client, and it supports atomic appends to multiple separate logs. The log will only overwrite space freed via advance_head.\n\nOur log is designed for storing low-level metadata and data in a cloud-scale production storage system. It is integrated into a production codebase, which incorporates it via Cargo.toml as just another Rust crate.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "To evaluate Verus’s utility for verifying production code, we developed a persistent circular log for byte-addressable storage devices such as Optane DC Persistent Memory [72].\n\nVerification Target. The log offers asynchronous append and synchronous advance_head operations to its storage system client, and it supports atomic appends to multiple separate logs. The log will only overwrite space freed via advance_head.\n\nOur log is designed for storing low-level metadata and data in a cloud-scale production storage system. It is integrated into a production codebase, which incorporates it via Cargo.toml as just another Rust crate.",
      "textWithCitationsRemoved": "To evaluate Verus’s utility for verifying production code, we developed a persistent circular log for byte-addressable storage devices.\n\nVerification Target. The log offers asynchronous append and synchronous advance_head operations to its storage system client, and it supports atomic appends to multiple separate logs. The log will only overwrite space freed via advance_head.\n\nOur log is designed for storing low-level metadata and data in a cloud-scale production storage system. It is integrated into a production codebase, which incorporates it via Cargo.toml as just another Rust crate."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Development Experience. We verify the implementation refines an abstract, infinite log; that all operations are atomic with respect to crashes; and that the log metadata is protected from corruption up to CRC. These properties are essential for persistent memory, which has a small persistence granularity and is at risk for fine-grained media errors, random bit flips, and stray writes. They are also especially valuable in cloud-scale storage, where crashing and corruption bugs too rare to detect with traditional testing still turn up.\n\nProduction integration is simple: Verus erases all but Rust content for tools other than the verifier; standard rustc sees only executable code and readily consumes it for the crates that the verified code depends on, such as a CRC crate, we write a specification and mark it trusted.\n\nTo simplify our proofs, our initial verified log converted each metadata structure to a byte slice before writing to persistent memory, incurring unnecessary copying in DRAM.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Development Experience. We verify the implementation refines an abstract, infinite log; that all operations are atomic with respect to crashes; and that the log metadata is protected from corruption up to CRC. These properties are essential for persistent memory, which has a small persistence granularity and is at risk for fine-grained media errors, random bit flips, and stray writes [73]. They are also especially valuable in cloud-scale storage, where crashing and corruption bugs too rare to detect with traditional testing still turn up.\n\nProduction integration is simple: Verus erases all but Rust content for tools other than the verifier; standard rustc sees only executable code and readily consumes it for the crates that the verified code depends on, such as a CRC crate, we write a specification and mark it trusted.\n\nTo simplify our proofs, our initial verified log converted each metadata structure to a byte slice before writing to persistent memory, incurring unnecessary copying in DRAM.",
      "textWithCitationsRemoved": "Development Experience. We verify the implementation refines an abstract, infinite log; that all operations are atomic with respect to crashes; and that the log metadata is protected from corruption up to CRC. These properties are essential for persistent memory, which has a small persistence granularity and is at risk for fine-grained media errors, random bit flips, and stray writes. They are also especially valuable in cloud-scale storage, where crashing and corruption bugs too rare to detect with traditional testing still turn up.\n\nProduction integration is simple: Verus erases all but Rust content for tools other than the verifier; standard rustc sees only executable code and readily consumes it for the crates that the verified code depends on, such as a CRC crate, we write a specification and mark it trusted.\n\nTo simplify our proofs, our initial verified log converted each metadata structure to a byte slice before writing to persistent memory, incurring unnecessary copying in DRAM."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Our latest version provides a serializable trait with spec methods to specify the byte-level layout of metadata structures. Structures serialized this way can be copied directly to persistent memory without the need for runtime conversion to a slice, removing conversion overhead while providing the same guarantees.\n\nEvaluation. Verus verifies the log implementation in 12s with a proof-to-code ratio of 3:9 (Figure 9), while offering correctness, crash safety, and metadata-corruption detection.\n\nWe evaluate performance on a 128GiB Optane Persistent Memory Module device. All log updates are written directly to the device through a 4GiB memory-mapped file in Ex4-DAX. We compare the latest verified log against libpmemlog from the state-of-the-art PMDK, and against the original log prototype.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Our latest version provides a serializable trait with spec methods to specify the byte-level layout of metadata structures. Structures serialized this way can be copied directly to persistent memory without the need for runtime conversion to a slice, removing conversion overhead while providing the same guarantees.\n\nEvaluation. Verus verifies the log implementation in 12s with a proof-to-code ratio of 3:9 (Figure 9), while offering correctness, crash safety, and metadata-corruption detection.\n\nWe evaluate performance on a 128GiB Optane Persistent Memory Module device. All log updates are written directly to the device through a 4GiB memory-mapped file in Ex4-DAX [74]. We compare the latest verified log against libpmemlog [75] from the state-of-the-art PMDK [76], and against the original log prototype.",
      "textWithCitationsRemoved": "Our latest version provides a serializable trait with spec methods to specify the byte-level layout of metadata structures. Structures serialized this way can be copied directly to persistent memory without the need for runtime conversion to a slice, removing conversion overhead while providing the same guarantees.\n\nEvaluation. Verus verifies the log implementation in 12s with a proof-to-code ratio of 3:9 (Figure 9), while offering correctness, crash safety, and metadata-corruption detection.\n\nWe evaluate performance on a 128GiB Optane Persistent Memory Module device. All log updates are written directly to the device through a 4GiB memory-mapped file in Ex4-DAX. We compare the latest verified log against libpmemlog from the state-of-the-art PMDK, and against the original log prototype."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Figure 14 compares the append throughput of all three systems with 95% confidence intervals. Each data point is 8GiB of appends (including operations to free space so the log can wrap around). The initial version of the verified log provided low throughput on small appends due to its extra copying; the latest version eliminates this overhead and achieves comparable throughput to libpmemlog.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "figure_image",
    "content": "Figure 14  summary:\nThis figure shows a bar graph comparing the append throughput of two systems: verified log and libpmemlog. The x-axis represents the append size in KiB, ranging from 0.125 to 256, while the y-axis shows throughput in MB/s, ranging from 0 to 1200. The graph includes three series for libpmemlog: PMDK, initial, and latest. Verified log consistently shows lower throughput compared to libpmemlog across all append sizes. The data suggests that libpmemlog, especially in its latest version, performs better in terms of throughput than the verified log.",
    "page": 14,
    "label": {
      "labelType": "Figure",
      "labelNumber": "14",
      "panelNumber": ""
    },
    "repositioned": true,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The current verified log and libpmemlog have similar throughput even though the verified log calculates CRCs and libpmemlog does not, because libpmemlog acquires and releases a lock on each append while the verified log uses no locks.\n\nSummary.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "The verified log shows that Verus can develop software that integrates naturally into production code bases.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "It also demonstrates that Verus supports reasoning about domain-specific properties, like crash safety, without “baking” such reasoning into Verus itself.",
    "page": 13,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "heading",
    "content": "[break0.7]5 Related Work[break0.7]",
    "page": 14,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Multiple groups have employed interactive theorem provers like Coq and Isabelle/HOL to verify systems. By default, these are less automated than SMT solvers: developers manually walk the verifier through the proof by applying tactics, leading to large proof-to-code ratios (e.g., over 20:1 for the initial version of seL4), despite some recent domain-specific improvements.",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Multiple groups [2, 3, 77–82] have employed interactive theorem provers like Coq [31] and Isabelle/HOL [83] to verify systems. By default, these are less automated than SMT solvers: developers manually walk the verifier through the proof by applying tactics, leading to large proof-to-code ratios (e.g., over 20:1 for the initial version of seL4 [84]), despite some recent domain-specific improvements [82].",
      "textWithCitationsRemoved": "Multiple groups have employed interactive theorem provers like Coq and Isabelle/HOL to verify systems. By default, these are less automated than SMT solvers: developers manually walk the verifier through the proof by applying tactics, leading to large proof-to-code ratios (e.g., over 20:1 for the initial version of seL4), despite some recent domain-specific improvements."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "In contrast, Verus continues a line of work on program verifiers, which focus on verifying programs written in a particular language. Using solvers, these tools typically offer more automation “out of the box” (e.g., the Ironclad project had a proof-to-code ratio of 5:1).",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "In contrast, Verus continues a line of work on program verifiers [11, 34, 35, 64], which focus on verifying programs written in a particular language. Using solvers, these tools typically offer more automation “out of the box” (e.g., the Ironclad project [12] had a proof-to-code ratio of 5:1).",
      "textWithCitationsRemoved": "In contrast, Verus continues a line of work on program verifiers, which focus on verifying programs written in a particular language. Using solvers, these tools typically offer more automation “out of the box” (e.g., the Ironclad project had a proof-to-code ratio of 5:1)."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Verus benefits from prior work on using ownership type systems to simplify memory reasoning in systems code. For example, a prior study on Linear Dafny quantifies the benefits of using ownership to reason about memory access in complex systems, and shows how ownership can co-exist with traditional memory reasoning. Linear Dafny’s ownership types are considerably less sophisticated than Rust’s, however, Linear Dafny in turn builds on Cogent’s purely functional support for borrowing and on early work by Wadler.",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Verus benefits from prior work on using ownership type systems to simplify memory reasoning in systems code. For example, a prior study on Linear Dafny [16] quantifies the benefits of using ownership to reason about memory access in complex systems [67], and shows how ownership can co-exist with traditional memory reasoning. Linear Dafny’s ownership types are considerably less sophisticated than Rust’s, however, Linear Dafny in turn builds on Cogent’s purely functional support for borrowing [85] and on early work by Wadler [86].",
      "textWithCitationsRemoved": "Verus benefits from prior work on using ownership type systems to simplify memory reasoning in systems code. For example, a prior study on Linear Dafny quantifies the benefits of using ownership to reason about memory access in complex systems, and shows how ownership can co-exist with traditional memory reasoning. Linear Dafny’s ownership types are considerably less sophisticated than Rust’s, however, Linear Dafny in turn builds on Cogent’s purely functional support for borrowing and on early work by Wadler."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Verus is one of several tools building on Rust. RustBelt focuses on manually verifying unsafe Rust code using Coq. Prusti encodes Rust code into the Viper verification framework, which leads Prusti to essentially re-verify Rust’s typechecking, resulting in larger SMT queries. While conceptually similar to Verus, Creusot lacks Verus’s ability to reason about ghost resources. As §4.1 shows, Verus verifies equivalent code faster than either Prusti or Creusot. Aeneas translates Rust code into a pure functional form that the developer then reasons about in a separate proof assistant; this differs from Verus’s intrinsic approach where the developer writes code and proofs directly in Rust. In addition, Prusti, Creusot, and Aeneas do not offer EPR-style automation, nor do they include support for system-specific idioms or reasoning about concurrency.",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Verus is one of several tools building on Rust. RustBelt [87] focuses on manually verifying unsafe Rust code using Coq. Prusti [64] encodes Rust code into the Viper verification framework [88], which leads Prusti to essentially re-verify Rust’s typechecking, resulting in larger SMT queries. While conceptually similar to Verus, Creusot [65] lacks Verus’s ability to reason about ghost resources. As §4.1 shows, Verus verifies equivalent code faster than either Prusti or Creusot. Aeneas [89] translates Rust code into a pure functional form that the developer then reasons about in a separate proof assistant (currently Lean [32]); this differs from Verus’s intrinsic approach where the developer writes code and proofs directly in Rust. In addition, Prusti, Creusot, and Aeneas do not offer EPR-style automation, nor do they include support for system-specific idioms or reasoning about concurrency.",
      "textWithCitationsRemoved": "Verus is one of several tools building on Rust. RustBelt focuses on manually verifying unsafe Rust code using Coq. Prusti encodes Rust code into the Viper verification framework, which leads Prusti to essentially re-verify Rust’s typechecking, resulting in larger SMT queries. While conceptually similar to Verus, Creusot lacks Verus’s ability to reason about ghost resources. As §4.1 shows, Verus verifies equivalent code faster than either Prusti or Creusot. Aeneas translates Rust code into a pure functional form that the developer then reasons about in a separate proof assistant; this differs from Verus’s intrinsic approach where the developer writes code and proofs directly in Rust. In addition, Prusti, Creusot, and Aeneas do not offer EPR-style automation, nor do they include support for system-specific idioms or reasoning about concurrency."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Prior work on Verus focuses on Verus’s ghost ownership mechanism and formalizes the interactions between spec, proof, and executable code. It also shows how Verus can reason about unsafe Rust code using owned ghost variables.",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "Prior work on Verus [10] focuses on Verus’s ghost ownership mechanism and formalizes the interactions between spec, proof, and executable code. It also shows how Verus can reason about unsafe Rust code using owned ghost variables.",
      "textWithCitationsRemoved": "Prior work on Verus focuses on Verus’s ghost ownership mechanism and formalizes the interactions between spec, proof, and executable code. It also shows how Verus can reason about unsafe Rust code using owned ghost variables."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "This paper focuses on systems aspects of how Verus: one. Optimizes SMT performance via context pruning and the careful design of quantifier trigger-selection (section three point one); two. Provides the proof-free automation (section three point two) of tools like Ivy by allowing a developer to opt into the restricted EPR logic on a per-module basis, and then soundly connect such proofs to code written in unrestricted logic; three. Incorporates simple-to-invoke proof automation for nonlinear arithmetic, bit-vectors, and proof-by-computation, both to address systems-verification needs and to keep the main SMT encoding simple and efficient (section three point three); four. Introduces VerusSync (section three point four), a novel state-transition-based language to describe operations on ghost state embedded in code via Rust ownership types. Unlike other systems, VerusSync does not require the developer to understand or construct low-level resource algebras. While others have built individual systems using Verus, we evaluate the impact of Verus’s design choices through an extensive comparative evaluation (section four).",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": true,
    "citationReplacement": {
      "originalText": "This paper focuses on systems aspects of how Verus: 1. Optimizes SMT performance via context pruning and the careful design of quantifier trigger-selection (§3.1); 2. Provides the proof-free automation (§3.2) of tools like Ivy [7, 8, 18–22] by allowing a developer to opt into the restricted EPR logic on a per-module basis, and then soundly connect such proofs to code written in unrestricted logic; 3. Incorporates simple-to-invoke proof automation for nonlinear arithmetic, bit-vectors, and proof-by-computation, both to address systems-verification needs and to keep the main SMT encoding simple and efficient (§3.3); 4. Introduces VerusSync (§3.4), a novel state-transition-based language to describe operations on ghost state embedded in code via Rust ownership types. Unlike other systems [3, 29, 30] (or prior work on Verus [10]), VerusSync does not require the developer to understand or construct low-level resource algebras. While others have built individual systems using Verus [25–27], we evaluate the impact of Verus’s design choices through an extensive comparative evaluation (§4).",
      "textWithCitationsRemoved": "This paper focuses on systems aspects of how Verus: 1. Optimizes SMT performance via context pruning and the careful design of quantifier trigger-selection (§3.1); 2. Provides the proof-free automation (§3.2) of tools like Ivy by allowing a developer to opt into the restricted EPR logic on a per-module basis, and then soundly connect such proofs to code written in unrestricted logic; 3. Incorporates simple-to-invoke proof automation for nonlinear arithmetic, bit-vectors, and proof-by-computation, both to address systems-verification needs and to keep the main SMT encoding simple and efficient (§3.3); 4. Introduces VerusSync (§3.4), a novel state-transition-based language to describe operations on ghost state embedded in code via Rust ownership types. Unlike other systems, VerusSync does not require the developer to understand or construct low-level resource algebras. While others have built individual systems using Verus, we evaluate the impact of Verus’s design choices through an extensive comparative evaluation (§4)."
    },
    "replacedCitations": true,
    "mathSymbolFrequency": 2,
    "mathReplacement": {
      "originalText": "This paper focuses on systems aspects of how Verus: 1. Optimizes SMT performance via context pruning and the careful design of quantifier trigger-selection (§3.1); 2. Provides the proof-free automation (§3.2) of tools like Ivy by allowing a developer to opt into the restricted EPR logic on a per-module basis, and then soundly connect such proofs to code written in unrestricted logic; 3. Incorporates simple-to-invoke proof automation for nonlinear arithmetic, bit-vectors, and proof-by-computation, both to address systems-verification needs and to keep the main SMT encoding simple and efficient (§3.3); 4. Introduces VerusSync (§3.4), a novel state-transition-based language to describe operations on ghost state embedded in code via Rust ownership types. Unlike other systems, VerusSync does not require the developer to understand or construct low-level resource algebras. While others have built individual systems using Verus, we evaluate the impact of Verus’s design choices through an extensive comparative evaluation (§4).",
      "wordedReplacement": "This paper focuses on systems aspects of how Verus: one. Optimizes SMT performance via context pruning and the careful design of quantifier trigger-selection (section three point one); two. Provides the proof-free automation (section three point two) of tools like Ivy by allowing a developer to opt into the restricted EPR logic on a per-module basis, and then soundly connect such proofs to code written in unrestricted logic; three. Incorporates simple-to-invoke proof automation for nonlinear arithmetic, bit-vectors, and proof-by-computation, both to address systems-verification needs and to keep the main SMT encoding simple and efficient (section three point three); four. Introduces VerusSync (section three point four), a novel state-transition-based language to describe operations on ghost state embedded in code via Rust ownership types. Unlike other systems, VerusSync does not require the developer to understand or construct low-level resource algebras. While others have built individual systems using Verus, we evaluate the impact of Verus’s design choices through an extensive comparative evaluation (section four)."
    },
    "optimizedMath": true
  },
  {
    "type": "heading",
    "content": "[break0.7]6 Conclusion[break0.7]",
    "page": 14,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "text",
    "content": "Verus aims to consolidate the gains made by the systemverification community in a unified tool. By building on a mainstream language (Rust), Verus makes thesis available to a much broader audience of system developers. At the same time, by leveraging Rust and our carefully designed system-oriented features, Verus provides a higher-level starting point for future research in this area. Ultimately, we hope that Verus enables researchers to identify the exciting research challenges that emerge as we scale verification to new heights of system size and complexity.",
    "page": 14,
    "isStartCutOff": false,
    "isEndCutOff": false,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  },
  {
    "type": "end_marker",
    "content": "[break0.4]You have reached the end of the paper.[break0.4]",
    "page": 17,
    "hasCitations": false,
    "mathSymbolFrequency": 0
  }
]
